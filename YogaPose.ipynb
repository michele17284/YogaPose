{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import genericpath\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# force working on cpu due to memory limitation\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_margin(pil_img, top, right, bottom, left, color):\n",
    "    width, height = pil_img.size\n",
    "    new_width = width + right + left\n",
    "    new_height = height + top + bottom\n",
    "    result = Image.new(pil_img.mode, (new_width, new_height), color)\n",
    "    result.paste(pil_img, (left, top))\n",
    "    return result\n",
    "\n",
    "\n",
    "class YogaPoseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path, size=(256, 192), transform=None, example_images=None):\n",
    "        if example_images is None:\n",
    "\t        example_images = [\"0004225.jpg\", \"0000008.jpg\", \"0000313.jpg\"]\n",
    "        self.example_images = dict(zip(example_images, [None] * len(example_images)))\n",
    "        self.data_path = dataset_path\n",
    "        self.size = size\n",
    "        self.transform = transform\n",
    "        # call to init the data\n",
    "        self._init_data()\n",
    "\n",
    "    def _init_data(self):\n",
    "        images = list()\n",
    "\n",
    "        for _, directory_class in enumerate(os.listdir(self.data_path)):\n",
    "            class_path = os.path.join(self.data_path, directory_class)\n",
    "            for file_name in os.listdir(class_path):\n",
    "                f = cv2.imread(os.path.join(class_path, file_name), cv2.IMREAD_COLOR)\n",
    "                f = cv2.cvtColor(f, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                if self.transform is not None:\n",
    "                    f = self.transform(f)\n",
    "\n",
    "                data = torch.reshape(torch.FloatTensor(f), (3, self.size[0], self.size[1]))\n",
    "\n",
    "                # format example  images[x][0] -> (label, input)\n",
    "                # format example  images[x][1] -> [other information]\n",
    "                # images[x] -> ((class_id, image_tensor), [filename])\n",
    "                if file_name in self.example_images.keys(): self.example_images[file_name] = len(images)\n",
    "                images.append((int(directory_class), data))\n",
    "\n",
    "\n",
    "        np.random.shuffle(images)\n",
    "        self.images = images\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns the number of samples in our dataset\n",
    "        return len(self.images)\n",
    "\n",
    "    def getData(self):\n",
    "        return self.images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            idx: the index of the sample\n",
    "\n",
    "        Returns: a tuple (class, input) for the given sample\n",
    "\n",
    "        \"\"\"\n",
    "        return self.images[idx]\n",
    "\n",
    "    def get_example_images(self ):\n",
    "        return self.example_images\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        #print(data)\n",
    "        Xs = torch.stack([x[1] for x in data])\n",
    "        y = torch.stack([torch.tensor(x[0]) for x in data])\n",
    "        return Xs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DATASET_PATH = './data/images/'\n",
    "ANNOTATION_PATH = './data/annotations/'\n",
    "MODEL_NAME = \"tpr_a4_256x192\"\n",
    "norm_transform = T.Compose([T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), ])\n",
    "dataset = YogaPoseDataset(DATASET_PATH, transform=norm_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/orlando/.cache/torch/hub/yangsenius_TransPose_main\n",
      "/home/orlando/.cache/torch/hub/yangsenius_TransPose_main/lib/models/transpose_r.py:333: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = temperature ** (2 * (dim_t // 2) / one_direction_feats)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Load pretrained weights from url: https://github.com/yangsenius/TransPose/releases/download/Hub/tp_r_256x192_enc4_d256_h1024_mh8.pth\n",
      "Successfully loaded model  (on cpu) with pretrained weights!\n"
     ]
    },
    {
     "data": {
      "text/plain": "TransPoseR(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (reduce): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (global_encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (1): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (2): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (3): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (deconv_layers): Sequential(\n    (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (final_layer): Conv2d(256, 17, kernel_size=(1, 1), stride=(1, 1))\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get model from torch hub\n",
    "assert MODEL_NAME in [\"tpr_a4_256x192\", \"tph_a4_256x192\"]\n",
    "\n",
    "transpose_model = torch.hub.load('yangsenius/TransPose:main', MODEL_NAME, pretrained=True)\n",
    "transpose_model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from TransPose.lib.config import cfg\n",
    "from TransPose.lib.utils import transforms\n",
    "from TransPose.lib.core.inference import get_final_preds\n",
    "from TransPose.visualize import inspect_atten_map_by_locations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "train_split_position = (len(dataset) // 10) * 8\n",
    "val_split_position = train_split_position+len(dataset)//10\n",
    "trainset = dataset[:train_split_position]\n",
    "valset = dataset[train_split_position:val_split_position]\n",
    "testset = dataset[val_split_position:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "OUT_DIR = \"./out/\"\n",
    "idx = 0\n",
    "\n",
    "if not os.path.isdir(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class PoseClassifier(nn.Module):\n",
    "    def __init__(self, n_class,\n",
    "                 transpose_model,device=device, fine_tune=False, pretrained=True):\n",
    "        super(PoseClassifier, self).__init__()\n",
    "        layers = []\n",
    "        dropout = 0.5\n",
    "        hidden_layers = [128, 512, 512, 512, 512, 256, 128, 128]\n",
    "        self.tph = transpose_model\n",
    "        layers.append(nn.Conv2d(17, 128, 3, padding=1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "        #'''\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.conv1 = nn.Conv2d(17, hidden_layers[0], 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_layers[0])\n",
    "        self.pool1 = nn.MaxPool2d((2, 2), 2)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d((3, 3), 3)\n",
    "        self.conv2 = nn.Conv2d(hidden_layers[0], hidden_layers[1], 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_layers[1])\n",
    "        self.conv3 = nn.Conv2d(hidden_layers[1], hidden_layers[2], 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(hidden_layers[2])\n",
    "        self.conv4 = nn.Conv2d(hidden_layers[2], hidden_layers[3], 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(hidden_layers[3])\n",
    "        self.conv5 = nn.Conv2d(hidden_layers[3], hidden_layers[4], 3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(hidden_layers[4])\n",
    "        #self.conv6 = nn.Conv2d(hidden_layers[4], hidden_layers[-1], 3, padding=1)\n",
    "        #self.conv7 = nn.Conv2d(hidden_layers[5], hidden_layers[6], 3, padding=1)\n",
    "        #self.conv8 = nn.Conv2d(hidden_layers[6], hidden_layers[7], 3, padding=1)\n",
    "        #'''\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin1 = nn.Linear(hidden_layers[4],hidden_layers[-1])\n",
    "        self.classifier = nn.Linear(hidden_layers[-1],n_class)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.tph(x)\n",
    "        #print(out.size(),\"AFTER TPH\")\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        #print(out.size(),\"AFTER CONV1\")\n",
    "        out = self.pool1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        #print(out.size(),\"AFTER CONV2\")\n",
    "        out = self.pool1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        #print(out.size(),\"AFTER CONV3\")\n",
    "        out = self.pool2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.conv4(out)\n",
    "        out = self.bn4(out)\n",
    "        #print(out.size(),\"AFTER CONV4\")\n",
    "        out = self.pool2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.conv5(out)\n",
    "        out = self.bn5(out)\n",
    "        #print(out.size(),\"AFTER CONV5\")\n",
    "        #out = self.pool1(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.lin1(out)\n",
    "        '''\n",
    "        out = self.pool1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.conv6(out)\n",
    "\n",
    "        #print(out.size(),\"AFTER CONV6\")\n",
    "        '''\n",
    "\n",
    "\n",
    "        out = self.flatten(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER FLATTEN\")\n",
    "\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "num_classes = 107\n",
    "model = PoseClassifier(n_class=num_classes, transpose_model=transpose_model)\n",
    "num_epochs = 50\n",
    "batch_size = 12\n",
    "learning_rate = 1e-4\n",
    "learning_rate_decay = 0.99\n",
    "params_to_update = model.parameters()\n",
    "\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "fine_tune = False\n",
    "if fine_tune:\n",
    "    params_to_update = []\n",
    "    for param in model.tph.parameters():\n",
    "        param.requires_grad = False\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad == True:\n",
    "            params_to_update.append(p)\n",
    "else:\n",
    "    params_to_update = model.parameters()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=False,collate_fn=dataset.collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=valset,batch_size=batch_size,shuffle=False,collate_fn=dataset.collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size,shuffle=False,collate_fn=dataset.collate_fn)\n",
    "# Train the model\n",
    "lr = learning_rate\n",
    "total_step = len(train_loader)\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "best_accuracy = None\n",
    "accuracy_val = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "data": {
      "text/plain": "4792"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "len(train_loader.dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "params_to_update = model.parameters()\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
    "# Train the model\n",
    "lr = learning_rate\n",
    "total_step = len(train_loader)\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "best_accuracy = None\n",
    "accuracy_val = []\n",
    "accuracy_test = []\n",
    "#best_model = type(model)(num_classes, fine_tune, pretrained) # get a new instance\n",
    "def train(model,num_epochs=num_epochs,lr=learning_rate):\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loss_iter = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #print(outputs,labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_iter += loss.item()\n",
    "\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        accuracy_test.append(accuracy)\n",
    "        print('Training accuracy is: {} %'.format(accuracy))\n",
    "        loss_train.append(loss_iter / (len(train_loader) * batch_size))\n",
    "\n",
    "        # Code to update the lr\n",
    "        lr *= learning_rate_decay\n",
    "        update_lr(optimizer, lr)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            loss_iter = 0\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss_iter += loss.item()\n",
    "            loss_val.append(loss_iter / (len(val_loader) * batch_size))\n",
    "            accuracy = 100 * correct / total\n",
    "            accuracy_val.append(accuracy)\n",
    "            print('Validation accuracy is: {} %'.format(accuracy))\n",
    "            early_stop = False\n",
    "            patience = 3\n",
    "            if epoch > patience - 1:\n",
    "                for j in range(patience - 1):\n",
    "                    if max(accuracy_val) > list(reversed(accuracy_val))[j]:\n",
    "                        if \"not_improving_epochs\" in locals():\n",
    "                            not_improving_epochs += 1\n",
    "                        else:\n",
    "                            not_improving_epochs = 1\n",
    "                        print('Not saving the model')\n",
    "                    else:\n",
    "                        not_improving_epochs = 0\n",
    "                        best_model = model\n",
    "                        print(\"Saving the model\")\n",
    "                        break\n",
    "                    if not_improving_epochs >= patience:\n",
    "                        early_stop = True\n",
    "                        print('Early stopping')\n",
    "                        break\n",
    "                    break\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.plot(loss_train, 'r', label='Train loss')\n",
    "    plt.plot(loss_val, 'g', label='Val loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(3)\n",
    "    plt.plot(accuracy_val, 'r', label='Val accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return {\"Loss/train\": loss_train, \"Loss/val\": loss_val, \"Accuracy/train\":accuracy_val, \"Accuracy/val\": accuracy_test }\n",
    "\n",
    "def test(model):\n",
    "    with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            loss_iter = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss_iter += loss.item()\n",
    "            loss_test =(loss_iter / (len(test_loader) * batch_size))\n",
    "            accuracy = 100 * correct / total\n",
    "            print('Test accuracy is: {} %'.format(accuracy))\n",
    "            print('Test Loss: {:.4f}'.format(loss_test))\n",
    "    return {\"Accuracy/test\": accuracy, \"Loss/test\": loss_test}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/400], Loss: 4.7467\n",
      "Epoch [1/3], Step [200/400], Loss: 4.6803\n",
      "Epoch [1/3], Step [300/400], Loss: 4.5510\n",
      "Epoch [1/3], Step [400/400], Loss: 4.6808\n",
      "Training accuracy is: 1.7320534223706177 %\n",
      "Validation accuracy is: 2.337228714524207 %\n",
      "Epoch [2/3], Step [100/400], Loss: 4.6503\n",
      "Epoch [2/3], Step [200/400], Loss: 4.4019\n",
      "Epoch [2/3], Step [300/400], Loss: 4.8228\n",
      "Epoch [2/3], Step [400/400], Loss: 4.3256\n",
      "Training accuracy is: 2.963272120200334 %\n",
      "Validation accuracy is: 2.5041736227045077 %\n",
      "Epoch [3/3], Step [100/400], Loss: 4.3057\n",
      "Epoch [3/3], Step [200/400], Loss: 4.0142\n",
      "Epoch [3/3], Step [300/400], Loss: 4.4980\n",
      "Epoch [3/3], Step [400/400], Loss: 4.8100\n",
      "Training accuracy is: 3.714524207011686 %\n",
      "Validation accuracy is: 3.672787979966611 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_values = train(model,num_epochs=3,lr=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is: 4.159733777038269 %\n",
      "Test Loss: 0.3752\n"
     ]
    }
   ],
   "source": [
    "test_values = test(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_model_code():\n",
    "    import inspect, sys\n",
    "    from IPython.core.magics.code import extract_symbols\n",
    "\n",
    "    def new_getfile(object, _old_getfile=inspect.getfile):\n",
    "        if not inspect.isclass(object):\n",
    "            return _old_getfile(object)\n",
    "\n",
    "        # Lookup by parent module (as in current inspect)\n",
    "        if hasattr(object, '__module__'):\n",
    "            object_ = sys.modules.get(object.__module__)\n",
    "            if hasattr(object_, '__file__'):\n",
    "                return object_.__file__\n",
    "\n",
    "        # If parent module is __main__, lookup by methods (NEW)\n",
    "        for name, member in inspect.getmembers(object):\n",
    "            if inspect.isfunction(member) and object.__qualname__ + '.' + member.__name__ == member.__qualname__:\n",
    "                return inspect.getfile(member)\n",
    "        else:\n",
    "            raise TypeError('Source for {!r} not found'.format(object))\n",
    "\n",
    "    inspect.getfile = new_getfile\n",
    "    obj = PoseClassifier\n",
    "    cell_code = \"\".join(inspect.linecache.getlines(new_getfile(obj)))\n",
    "    class_code = extract_symbols(cell_code, obj.__name__)[0][0]\n",
    "    return class_code\n",
    "\n",
    "def save_run(train_dict = None, test_dict= None, save_examples = False, ):\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    import numbers, json\n",
    "    def get_next_logdir():\n",
    "        from datetime import datetime\n",
    "        now = datetime.now()\n",
    "        date_time = now.strftime(\"%d_%b[%H-%M-%S]\")\n",
    "        multi_val_index = 1\n",
    "        logs_dir = OUT_DIR + \"logs/\"\n",
    "        dir_name = logs_dir + date_time\n",
    "        while os.path.exists(dir_name):\n",
    "            multi_val_index += 1\n",
    "            dir_name = \"\".join([logs_dir, date_time, \"(\", str(multi_val_index), \")\"])\n",
    "        return dir_name\n",
    "\n",
    "    def save_log(value_dict):\n",
    "        for key,value in value_dict.items():\n",
    "            if isinstance(value, numbers.Number):\n",
    "                writer.add_scalar(key, value, 0)\n",
    "            else:\n",
    "                for e, e_value in enumerate(value):\n",
    "                    writer.add_scalar(key, e_value, e)\n",
    "\n",
    "    dir_name = get_next_logdir()\n",
    "    model_path = os.path.join(dir_name, \"model.ckpt\")\n",
    "    model_json_path = os.path.join(dir_name, \"model_params.json\")\n",
    "    model_classcode_path = os.path.join(dir_name, \"model_class_code.txt\")\n",
    "    example_images_path = os.path.join(dir_name, \"example_images\")\n",
    "    writer = SummaryWriter(log_dir=dir_name)\n",
    "    model_dict = { \"params\": {\"num_classes\": num_classes, \"num_epochs\": num_epochs, \"batch_size\": batch_size, \"learning_rate\": learning_rate, \"learning_rate_decay\": learning_rate_decay}}\n",
    "\n",
    "    print(\"Saving {} in {}\".format(\"model\", model_path), end=\" \")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(\"DONE\")\n",
    "\n",
    "    print(\"Saving {} in {}\".format(\"Logs (if any)\", dir_name), end=\" \")\n",
    "    if train_dict is not None: save_log(train_dict)\n",
    "    if test_dict is not None:save_log(test_dict)\n",
    "    writer.close()\n",
    "    print(\"DONE\")\n",
    "\n",
    "    print(\"Saving {} in {}\".format(\"parameters\", model_json_path), end=\" \")\n",
    "    with open(model_json_path, \"w\") as jf:\n",
    "        json.dump(model_dict, jf)\n",
    "    print(\"DONE\")\n",
    "\n",
    "    print(\"Saving {} in {}\".format(\"class code\", model_classcode_path), end=\" \")\n",
    "    with open(model_classcode_path, \"w\") as f:\n",
    "        f.write(get_model_code())\n",
    "    print(\"DONE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model in ./out/logs/12_Dec[21-50-10]/model.ckpt DONE\n",
      "Saving Logs (if any) in ./out/logs/12_Dec[21-50-10] DONE\n",
      "Saving parameters in ./out/logs/12_Dec[21-50-10]/model_params.json DONE\n",
      "Saving class code in ./out/logs/12_Dec[21-50-10]/model_class_code.txt DONE\n"
     ]
    }
   ],
   "source": [
    "save_run(train_values, test_values, save_examples=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}