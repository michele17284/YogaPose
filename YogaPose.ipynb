{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import genericpath\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# force working on cpu due to memory limitation\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_margin(pil_img, top, right, bottom, left, color):\n",
    "    width, height = pil_img.size\n",
    "    new_width = width + right + left\n",
    "    new_height = height + top + bottom\n",
    "    result = Image.new(pil_img.mode, (new_width, new_height), color)\n",
    "    result.paste(pil_img, (left, top))\n",
    "    return result\n",
    "\n",
    "\n",
    "class YogaPoseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path, size=(256, 192), transform=None):\n",
    "        self.data_path = dataset_path\n",
    "        self.size = size\n",
    "        self.transform = transform\n",
    "\n",
    "        # call to init the data\n",
    "        self._init_data()\n",
    "\n",
    "    def _init_data(self):\n",
    "        images = list()\n",
    "\n",
    "        for _, directory_class in enumerate(os.listdir(self.data_path)):\n",
    "            class_path = os.path.join(self.data_path, directory_class)\n",
    "            for file_name in os.listdir(class_path):\n",
    "                f = cv2.imread(os.path.join(class_path, file_name), cv2.IMREAD_COLOR)\n",
    "                f = cv2.cvtColor(f, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                if self.transform is not None:\n",
    "                    f = self.transform(f)\n",
    "\n",
    "                data = torch.reshape(torch.FloatTensor(f), (3, self.size[0], self.size[1]))\n",
    "\n",
    "                # format example  images[x][0] -> (label, input)\n",
    "                # format example  images[x][1] -> [other information]\n",
    "                # images[x] -> ((class_id, image_tensor), [filename])\n",
    "                images.append((int(directory_class), data))\n",
    "\n",
    "        np.random.shuffle(images)\n",
    "        self.images = images\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns the number of samples in our dataset\n",
    "        return len(self.images)\n",
    "\n",
    "    def getData(self):\n",
    "        return self.images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            idx: the index of the sample\n",
    "\n",
    "        Returns: a tuple (class, input) for the given sample\n",
    "\n",
    "        \"\"\"\n",
    "        return self.images[idx]\n",
    "\n",
    "    def getFileName(self, idx):\n",
    "        return str(self.images[idx][1][0])\n",
    "\n",
    "    def getOriginalImage(self, idx):\n",
    "        class_path = os.path.join(self.data_path, str(self.images[idx][0][0]))\n",
    "        out = cv2.imread(os.path.join(class_path, self.getFileName(idx)), cv2.IMREAD_COLOR)\n",
    "        print(self.getFileName(idx))\n",
    "        return out\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        #print(data)\n",
    "        Xs = torch.stack([x[1] for x in data])\n",
    "        y = torch.stack([torch.tensor(x[0]) for x in data])\n",
    "        return Xs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DATASET_PATH = './data/images/'\n",
    "ANNOTATION_PATH = './data/annotations/'\n",
    "MODEL_NAME = \"tpr_a4_256x192\"\n",
    "norm_transform = T.Compose([T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), ])\n",
    "dataset = YogaPoseDataset(DATASET_PATH, transform=norm_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Load pretrained weights from url: https://github.com/yangsenius/TransPose/releases/download/Hub/tp_r_256x192_enc4_d256_h1024_mh8.pth\n",
      "Successfully loaded model  (on cpu) with pretrained weights!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/orlando/.cache/torch/hub/yangsenius_TransPose_main\n"
     ]
    },
    {
     "data": {
      "text/plain": "TransPoseR(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (reduce): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (global_encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (1): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (2): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n      (3): TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (deconv_layers): Sequential(\n    (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (final_layer): Conv2d(256, 17, kernel_size=(1, 1), stride=(1, 1))\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get model from torch hub\n",
    "assert MODEL_NAME in [\"tpr_a4_256x192\", \"tph_a4_256x192\"]\n",
    "\n",
    "model = torch.hub.load('yangsenius/TransPose:main', MODEL_NAME, pretrained=True)\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from TransPose.lib.config import cfg\n",
    "from TransPose.lib.utils import transforms\n",
    "from TransPose.lib.core.inference import get_final_preds\n",
    "from TransPose.visualize import inspect_atten_map_by_locations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "train_split_position = (len(dataset) // 10) * 8\n",
    "val_split_position = train_split_position+len(dataset)//10\n",
    "trainset = dataset[:train_split_position]\n",
    "valset = dataset[train_split_position:val_split_position]\n",
    "testset = dataset[val_split_position:]\n",
    "#trainset = dataset[:100]\n",
    "#print(trainset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "OUT_DIR = \"./out/\"\n",
    "idx = 0\n",
    "\n",
    "if not os.path.isdir(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nwith torch.no_grad():\\n\\tmodel.eval()\\n\\timg = dataset[idx][1]\\n\\n\\tinputs = torch.cat([img.to(device)]).unsqueeze(0)\\n\\toutputs = model(inputs)\\n\\n\\tif isinstance(outputs, list):\\n\\t\\toutput = outputs[-1]\\n\\telse:\\n\\t\\toutput = outputs\\n\\n\\tif cfg.TEST.FLIP_TEST:\\n\\t\\tinput_flipped = np.flip(inputs.cpu().numpy(), 3).copy()\\n\\t\\tinput_flipped = torch.from_numpy(input_flipped).cuda()\\n\\t\\toutputs_flipped = model(input_flipped)\\n\\n\\t\\tif isinstance(outputs_flipped, list):\\n\\t\\t\\toutput_flipped = outputs_flipped[-1]\\n\\t\\telse:\\n\\t\\t\\toutput_flipped = outputs_flipped\\n\\n\\t\\toutput_flipped = transforms.flip_back(output_flipped.cpu().numpy(), dataset.flip_pairs)\\n\\t\\toutput_flipped = torch.from_numpy(output_flipped.copy()).cuda()\\n\\n\\t\\toutput = (output + output_flipped) * 0.5\\n\\n\\tpreds, maxvals = get_final_preds(cfg, output.clone().cpu().numpy(), None, None, transform_back=False)\\n\\n# from heatmap_coord to original_image_coord\\nquery_locations = np.array([p * 4 + 0.5 for p in preds[0]])\\n\\ninspect_atten_map_by_locations(img, model, query_locations, model_name=\"transposer\", mode=\\'dependency\\', save_img=True, threshold=0.0, outinfo=(OUT_DIR, dataset.getFileName(idx)))\\n\\ncv2.imwrite(OUT_DIR + dataset.getFileName(idx) + \"_original_img.jpg\", dataset.getOriginalImage(idx))\\n'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "with torch.no_grad():\n",
    "\tmodel.eval()\n",
    "\timg = dataset[idx][1]\n",
    "\n",
    "\tinputs = torch.cat([img.to(device)]).unsqueeze(0)\n",
    "\toutputs = model(inputs)\n",
    "\n",
    "\tif isinstance(outputs, list):\n",
    "\t\toutput = outputs[-1]\n",
    "\telse:\n",
    "\t\toutput = outputs\n",
    "\n",
    "\tif cfg.TEST.FLIP_TEST:\n",
    "\t\tinput_flipped = np.flip(inputs.cpu().numpy(), 3).copy()\n",
    "\t\tinput_flipped = torch.from_numpy(input_flipped).cuda()\n",
    "\t\toutputs_flipped = model(input_flipped)\n",
    "\n",
    "\t\tif isinstance(outputs_flipped, list):\n",
    "\t\t\toutput_flipped = outputs_flipped[-1]\n",
    "\t\telse:\n",
    "\t\t\toutput_flipped = outputs_flipped\n",
    "\n",
    "\t\toutput_flipped = transforms.flip_back(output_flipped.cpu().numpy(), dataset.flip_pairs)\n",
    "\t\toutput_flipped = torch.from_numpy(output_flipped.copy()).cuda()\n",
    "\n",
    "\t\toutput = (output + output_flipped) * 0.5\n",
    "\n",
    "\tpreds, maxvals = get_final_preds(cfg, output.clone().cpu().numpy(), None, None, transform_back=False)\n",
    "\n",
    "# from heatmap_coord to original_image_coord\n",
    "query_locations = np.array([p * 4 + 0.5 for p in preds[0]])\n",
    "\n",
    "inspect_atten_map_by_locations(img, model, query_locations, model_name=\"transposer\", mode='dependency', save_img=True, threshold=0.0, outinfo=(OUT_DIR, dataset.getFileName(idx)))\n",
    "\n",
    "cv2.imwrite(OUT_DIR + dataset.getFileName(idx) + \"_original_img.jpg\", dataset.getOriginalImage(idx))\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class PoseClassifier(nn.Module):\n",
    "    def __init__(self, n_class,\n",
    "                 transpose_model,device=device, fine_tune=False, pretrained=True):\n",
    "        super(PoseClassifier, self).__init__()\n",
    "        layers = []\n",
    "        dropout = 0.5\n",
    "        hidden_layers = [128, 512, 512, 512, 512, 256, 128, 128]\n",
    "        self.tph = transpose_model\n",
    "        layers.append(nn.Conv2d(17, 128, 3, padding=1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "        #'''\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.conv1 = nn.Conv2d(17, hidden_layers[0], 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_layers[0])\n",
    "        self.pool1 = nn.MaxPool2d((2, 2), 2)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d((3, 3), 3)\n",
    "        self.conv2 = nn.Conv2d(hidden_layers[0], hidden_layers[1], 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_layers[1])\n",
    "        self.conv3 = nn.Conv2d(hidden_layers[1], hidden_layers[2], 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(hidden_layers[2])\n",
    "        self.conv4 = nn.Conv2d(hidden_layers[2], hidden_layers[3], 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(hidden_layers[3])\n",
    "        self.conv5 = nn.Conv2d(hidden_layers[3], hidden_layers[4], 3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(hidden_layers[4])\n",
    "        #self.conv6 = nn.Conv2d(hidden_layers[4], hidden_layers[-1], 3, padding=1)\n",
    "        #self.conv7 = nn.Conv2d(hidden_layers[5], hidden_layers[6], 3, padding=1)\n",
    "        #self.conv8 = nn.Conv2d(hidden_layers[6], hidden_layers[7], 3, padding=1)\n",
    "        #'''\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin1 = nn.Linear(hidden_layers[4],hidden_layers[-1])\n",
    "        self.classifier = nn.Linear(hidden_layers[-1],n_class)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.tph(x)\n",
    "        #print(out.size(),\"AFTER TPH\")\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        #print(out.size(),\"AFTER CONV1\")\n",
    "        out = self.pool1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        #print(out.size(),\"AFTER CONV2\")\n",
    "        out = self.pool1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        #print(out.size(),\"AFTER CONV3\")\n",
    "        out = self.pool2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.conv4(out)\n",
    "        out = self.bn4(out)\n",
    "        #print(out.size(),\"AFTER CONV4\")\n",
    "        out = self.pool2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.conv5(out)\n",
    "        out = self.bn5(out)\n",
    "        #print(out.size(),\"AFTER CONV5\")\n",
    "        #out = self.pool1(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.lin1(out)\n",
    "        '''\n",
    "        out = self.pool1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER POOL\")\n",
    "        out = self.conv6(out)\n",
    "\n",
    "        #print(out.size(),\"AFTER CONV6\")\n",
    "        '''\n",
    "\n",
    "\n",
    "        out = self.flatten(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.size(),\"AFTER FLATTEN\")\n",
    "\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "num_classes = 107\n",
    "model = PoseClassifier(n_class=num_classes, transpose_model=model)\n",
    "num_epochs = 50\n",
    "batch_size = 12\n",
    "learning_rate = 1e-4\n",
    "learning_rate_decay = 0.99\n",
    "params_to_update = model.parameters()\n",
    "\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "fine_tune = False\n",
    "if fine_tune:\n",
    "    params_to_update = []\n",
    "    for param in model.tph.parameters():\n",
    "        param.requires_grad = False\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad == True:\n",
    "            params_to_update.append(p)\n",
    "else:\n",
    "    params_to_update = model.parameters()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=False,collate_fn=dataset.collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=valset,batch_size=batch_size,shuffle=False,collate_fn=dataset.collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size,shuffle=False,collate_fn=dataset.collate_fn)\n",
    "# Train the model\n",
    "lr = learning_rate\n",
    "total_step = len(train_loader)\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "best_accuracy = None\n",
    "accuracy_val = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "data": {
      "text/plain": "4792"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "len(train_loader.dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "params_to_update = model.parameters()\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
    "# Train the model\n",
    "lr = learning_rate\n",
    "total_step = len(train_loader)\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "best_accuracy = None\n",
    "accuracy_val = []\n",
    "accuracy_test = []\n",
    "#best_model = type(model)(num_classes, fine_tune, pretrained) # get a new instance\n",
    "def train(model,num_epochs=num_epochs,lr=learning_rate):\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loss_iter = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #print(outputs,labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_iter += loss.item()\n",
    "\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        accuracy_test.append(accuracy)\n",
    "        print('Training accuracy is: {} %'.format(accuracy))\n",
    "        loss_train.append(loss_iter / (len(train_loader) * batch_size))\n",
    "\n",
    "        # Code to update the lr\n",
    "        lr *= learning_rate_decay\n",
    "        update_lr(optimizer, lr)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            loss_iter = 0\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss_iter += loss.item()\n",
    "            loss_val.append(loss_iter / (len(val_loader) * batch_size))\n",
    "            accuracy = 100 * correct / total\n",
    "            accuracy_val.append(accuracy)\n",
    "            print('Validation accuracy is: {} %'.format(accuracy))\n",
    "            early_stop = False\n",
    "            patience = 3\n",
    "            if epoch > patience - 1:\n",
    "                for j in range(patience - 1):\n",
    "                    if max(accuracy_val) > list(reversed(accuracy_val))[j]:\n",
    "                        if \"not_improving_epochs\" in locals():\n",
    "                            not_improving_epochs += 1\n",
    "                        else:\n",
    "                            not_improving_epochs = 1\n",
    "                        print('Not saving the model')\n",
    "                    else:\n",
    "                        not_improving_epochs = 0\n",
    "                        best_model = model\n",
    "                        print(\"Saving the model\")\n",
    "                        break\n",
    "                    if not_improving_epochs >= patience:\n",
    "                        early_stop = True\n",
    "                        print('Early stopping')\n",
    "                        break\n",
    "                    break\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.plot(loss_train, 'r', label='Train loss')\n",
    "    plt.plot(loss_val, 'g', label='Val loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(3)\n",
    "    plt.plot(accuracy_val, 'r', label='Val accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return {\"Loss/train\": loss_train, \"Loss/val\": loss_val, \"Accuracy/train\":accuracy_val, \"Accuracy/val\": accuracy_test }\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            loss_iter = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss_iter += loss.item()\n",
    "            loss_test =(loss_iter / (len(test_loader) * batch_size))\n",
    "            accuracy = 100 * correct / total\n",
    "            print('Test accuracy is: {} %'.format(accuracy))\n",
    "            print('Test Loss: {:.4f}'.format(loss_test))\n",
    "    return {\"Accuracy/test\": accuracy, \"Loss/test\": loss_test}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/400], Loss: 3.1050\n",
      "Epoch [1/3], Step [200/400], Loss: 2.5237\n",
      "Epoch [1/3], Step [300/400], Loss: 3.3580\n",
      "Epoch [1/3], Step [400/400], Loss: 3.0986\n",
      "Training accuracy is: 14.002504173622704 %\n",
      "Validation accuracy is: 20.03338898163606 %\n",
      "Epoch [2/3], Step [100/400], Loss: 3.1163\n",
      "Epoch [2/3], Step [200/400], Loss: 2.4794\n",
      "Epoch [2/3], Step [300/400], Loss: 3.4917\n",
      "Epoch [2/3], Step [400/400], Loss: 2.5704\n",
      "Training accuracy is: 16.381469115191987 %\n",
      "Validation accuracy is: 22.036727879799667 %\n",
      "Epoch [3/3], Step [100/400], Loss: 3.1796\n",
      "Epoch [3/3], Step [200/400], Loss: 2.4716\n",
      "Epoch [3/3], Step [300/400], Loss: 3.4698\n",
      "Epoch [3/3], Step [400/400], Loss: 2.6776\n",
      "Training accuracy is: 19.51168614357262 %\n",
      "Validation accuracy is: 25.375626043405678 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjGUlEQVR4nO3de5yV497H8c8Po5SolMNW7YltS+cyknLoRGnTAbVVBiVRcgwb7ce2nUKkp9jZkSgpHVBSEkVP2qUpHdRoC0XpLB2kw0zX88e1yirTzJqate51+L5fr15m7rXWrJ97lm+X677u62fOOUREJPEcFXQBIiJyeBTgIiIJSgEuIpKgFOAiIglKAS4ikqCOieWblStXzqWnp8fyLUVEEt68efM2OufKH3w8pgGenp5OVlZWLN9SRCThmdnKvI5rCkVEJEEpwEVEEpQCXEQkQcV0Djwve/bsYdWqVezcuTPoUlJa8eLFqVChAmlpaUGXIiIRCjzAV61aRalSpUhPT8fMgi4nJTnn2LRpE6tWraJy5cpBlyMiEQp8CmXnzp2cdNJJCu8AmRknnXSS/i9IJMEEHuCAwjsO6HcgknjiIsBFRJLW1q1wxx2wZUuR/+iUD/DGjRszZcqUA47179+f7t27H/I1jRo10g1JIlKwr7+G+vXhX/+C//u/Iv/xKR/gHTp0YNSoUQccGzVqFB06dAioooLl5OQEXYKIFGTKFKhXD9avh48+giuuKPK3SPkAv+aaa3j//ffZvXs3ACtWrODHH3/koosuonv37mRkZFCtWjX+8Y9/FPizHn30Uc477zyqV69Ot27d2NftaPny5TRr1oxatWpRt25dvvnmGwCefvppatSoQa1atXjggQeAA0f3GzduZN/eMa+99hqtWrWiSZMmNG3alO3bt9O0aVPq1q1LjRo1GD9+/P46hg0bRs2aNalVqxaZmZls27aNypUrs2fPHgC2bt16wPciUoScg759oWVLqFQJsrKgUaOovFXgywgPcNddsGBB0f7M2rWhf/9DPly2bFnq1avH5MmTad26NaNGjaJ9+/aYGU888QRly5YlNzeXpk2bsmjRImrWrHnIn9WzZ08efvhhADIzM5k4cSJXXnklnTp14oEHHqBt27bs3LmTvXv3MnnyZMaPH8+cOXMoUaIEP/30U4H/KvPnz2fRokWULVuWnJwc3nnnHU444QQ2btxI/fr1adWqFUuXLuXxxx9n1qxZlCtXjp9++olSpUrRqFEj3n//fdq0acOoUaO46qqrtOZbpKj9+it07Qpvvgnt2sHQoVCyZNTeLuVH4HDgNEr49Mno0aOpW7cuderUYcmSJSxdujTfnzN9+nTOP/98atSowbRp01iyZAnbtm1j9erVtG3bFvA3zJQoUYKPPvqIzp07U6JECcD/RVKQSy+9dP/znHM89NBD1KxZk2bNmrF69WrWrVvHtGnTaNeuHeXKlTvg53bt2pWhQ4cCMHToUDp37lzY0yQi+fnhB7joIhg5Ep54At56K6rhDfE2As9npBxNrVu35u6772b+/Pns2LGDc889l++++45nn32WuXPnUqZMGW688cZ810nv3LmTHj16kJWVRcWKFXnkkUcOa131Mcccw969e/f/zHAlwz4MI0aMYMOGDcybN4+0tDTS09Pzfb+GDRuyYsUKPvnkE3Jzc6levXqhaxORQ5g5E66+2o/Ax4+HK6+MydtqBA4cf/zxNG7cmC5duuwffW/dupWSJUty4oknsm7dOiZPnpzvz9gXnuXKlWP79u2MHTsWgFKlSlGhQgXeffddAHbt2sWOHTu49NJLGTp0KDt27ADYP4WSnp7OvHnzAPb/jLxs2bKFk08+mbS0NKZPn87KlX63ySZNmjBmzBg2bdp0wM8FuP766+nYsaNG3yJF6eWXoUkTOPFEmDMnZuENCvD9OnTowMKFC/cHeK1atahTpw5VqlShY8eONGzYMN/Xly5dmptvvpnq1avTvHlzzjvvvP2PDR8+nAEDBlCzZk0aNGjA2rVradGiBa1atSIjI4PatWvz7LPPAnDvvfcyaNAg6tSpw8aNGw/5fp06dSIrK4saNWowbNgwqlSpAkC1atXo3bs3l1xyCbVq1eKee+454DWbN2+O6xU2Igljzx647Tbo1s0H+Jw5cM45MS3B9q2UiIWMjAx38Prp7Oxszonxv3SqGjt2LOPHj2f48OF5Pq7fhUiE1q/3FylnzID77oM+feDoo6P2dmY2zzmXcfDx+JoDl6i5/fbbmTx5MpMmTQq6FJHE9sUX0KaND/ERI6Bjx8BKUYCniIEDBwZdgkjie+st6NwZTjrJX7g899xAyylwDtzMKprZdDNbamZLzOzO0PFHzGy1mS0I/Wl5uEXEchpH8qbfgUg+cnPhoYfg2muhbl1/c07A4Q2RjcBzgF7OuflmVgqYZ2ZTQ48975x79kgKKF68OJs2bdKWsgHatx948eLFgy5FJP5s2eKnSSZN8hcsBw6EY48NuiogggB3zq0B1oS+3mZm2cDpRVVAhQoVWLVqFRs2bCiqHymHYV9HHhEJs2wZtG4N33wDgwbBrbcGXdEBCjUHbmbpQB1gDtAQ6Glm1wNZ+FH65jxe0w3oBlCpUqXf/cy0tDR1gRGR+DNpEnToAMWKwccfw8UXB13R70S8DtzMjgfGAXc557YCg4Azgdr4Efpzeb3OOTfYOZfhnMsoX778kVcsIhJNzsHTT/vdA884A+bOjcvwhggD3MzS8OE9wjn3NoBzbp1zLtc5txd4GagXvTJFRGJgxw4/3/3AA9C+PXz2Gfzxj0FXdUiRrEIxYAiQ7ZzrF3b8tLCntQW+LPryRERi5Pvv4cIL/VLBPn38plShzebiVSRz4A2BTGCxmS0IHXsI6GBmtQEHrABuiUJ9IiLRN2MGXHMN7NoFEyf6vbwTQCSrUGYCea3v0y19IpL4XnoJbr/dz3dPmABnnx10RRHTZlYikpp27/bLArt3h8su85tRJVB4gwJcRFLRunXQtCn8+9/w4IN+5F26dNBVFZr2QhGR1DJ/vt+MauNGf6Hy2muDruiwaQQuIqlj5Eho2BDM/BLBBA5vUICLSCrIzYW//c2v8T7vPH9zTp06QVd1xDSFIiLJ7eef/S3xH3zgL1j27x83m1EdKQW4iCSv7Gy/GdWKFf6CZbduQVdUpBTgIpKcJk70UybHHQfTpvm7LJOM5sBFJLk4B08+Ca1awVln+eYLSRjeoBG4iCSTX36BLl1g9Gg/+n755bjfz+RIKMBFJDmsWOHXdy9aBM88A/fe65cLJjEFuIgkvk8/9ZtR7dnjGzG0aBF0RTGhOXARSVzOwYsvQrNmUK4cfP55yoQ3KMBFJFHt2uWXBfbs6UN7zhz485+DriqmFOAiknjWroUmTeCVV6B3bxg/Hk44IeiqYk5z4CKSWLKy/MXKzZt995z27YOuKDAagYtI4njjDb+m+5hj/GZUKRzeoAAXkUSQmwv33QeZmXDBBX4zqtq1g64qcJpCEZH4tnmz3/b1ww/9Bct+/SAtLeiq4oICXETi19KlfjOqlSv9XZVduwZdUVxRgItIfJowATp1gpIl4ZNPoEGDoCuKO5oDF5H4sncvPPaYH3lXqeJXnSi886QRuIjEj+3b4cYbYdw4uO46GDzYbwcreVKAi0h8+O47P+pesgSeew7uvjvpN6M6UgpwEQnetGl+TXduLkyeDJddFnRFCUFz4CISHOdg4EAf2Kec4td3K7wjpgAXkWDs2uWXBd5xB1xxBcyeDX/6U9BVJRQFuIjE3po10KgRvPoq/M//wNtvQ6lSQVeVcAoMcDOraGbTzWypmS0xszsPeryXmTkzKxe9MkUkaXz+OWRkwOLFMHYsPPooHKWx5OGI5KzlAL2cc1WB+sBtZlYVfLgDlwHfR69EEUkaw4bBxRfDscfCrFlw9dVBV5TQCgxw59wa59z80NfbgGzg9NDDzwP3Ay5qFYpI4svJ8csCb7jB35Qzdy7UrBl0VQmvUP/fYmbpQB1gjpm1BlY75xYW8JpuZpZlZlkbNmw4/EpFJDFt2uQ75vTv7y9YTpni25/JEYt4HbiZHQ+MA+7CT6s8hJ8+yZdzbjAwGCAjI0MjdZFU8uWX/uacVav8BcvOnYOuKKlENAI3szR8eI9wzr0NnAlUBhaa2QqgAjDfzE6NVqEikmDeeQfq14cdO3zXeIV3kYtkFYoBQ4Bs51w/AOfcYufcyc65dOdcOrAKqOucWxvVakUk/u3dC//8J1x1FVSr5jejql8/6KqSUiQj8IZAJtDEzBaE/rSMcl0ikoi2bYNrroFHHvEXLD/9FE4/vcCXyeEpcA7cOTcTyHdHmdAoXERS2Tff+Pnu7Gx4/nm4805tRhVl2sxKRI7cRx/91mB4yhRo1izYelKEbn8SkcPnnF8e2Lw5/OEPfn23wjtmFOAicnh27vQrS+6+20+d/Oc/cOaZQVeVUhTgIlJ4q1fDJZfA66/7C5Zjx2ozqgBoDlxECmf2bL9EcNs2v9a7TZugK0pZGoGLSOSGDvUj7+OO81MmCu9AKcBFpGB79vhlgV26+N0E586F6tWDrirlKcBFJH/7NqMaMMBfsJw8GcqWDboqQXPgIpKfRYv8NMmPP8Jrr/m7KyVuaAQuInkbNw4uuMD3rpwxQ+EdhxTgInKgvXvh4Yf9niY1a/rNqOrVC7oqyYOmUETkN1u3QmYmTJjgb9IZNAiKFQu6KjkEBbiIeMuX+zsqly3zFyx79tRmVHFOAS4i8OGH8Ne/wtFH+6+bNAm6IomA5sBFUplz8NxzcPnlULGiX9+t8E4YCnCRVPXrr3D99XDvvdC2LcyaBZUrB12VFIICXCQVrVrl76h84w147DEYMwaOPz7oqqSQNAcukmpmzfKbUf3yC7z7rr9wKQlJI3CRVPLKK9Cokd/6dfZshXeCU4CLpII9e/yywJtvhsaN4fPPfcd4SWgKcJFkt2EDXHYZvPiiv2D5/vtQpkzQVUkR0By4SDJbsMBvRrV2LQwfDtddF3RFUoQ0AhdJVmPGQMOGkJMDM2cqvJOQAlwk2ezdC717Q/v2ULu234wqIyPoqiQKNIUikky2bPEj7YkToWtXeOEFbUaVxBTgIsniv//1ywKXL/cXLLt312ZUSU4BLpIMPvgArr0W0tJg6lS/1luSnubARRKZc/DMM9CyJaSn+82oFN4po8AAN7OKZjbdzJaa2RIzuzN0/DEzW2RmC8zsQzP7Q/TLFZH9fv3Vz3f/7W/Qrh189pkPcUkZkYzAc4BezrmqQH3gNjOrCvR1ztV0ztUGJgIPR69METnA99/DhRfCyJHw5JMwahSULBl0VRJjBc6BO+fWAGtCX28zs2zgdOfc0rCnlQRcdEoUkQPMnAlXX+1H4BMmwBVXBF2RBKRQc+Bmlg7UAeaEvn/CzH4AOnGIEbiZdTOzLDPL2rBhwxGWK5LiBg/2DRdOPBHmzFF4p7iIA9zMjgfGAXc557YCOOd6O+cqAiOAnnm9zjk32DmX4ZzLKF++fFHULJJ6du/2ywJvuQWaNvWbUZ1zTtBVScAiCnAzS8OH9wjn3Nt5PGUEcHVRFiYiIevXQ7Nm8NJLcP/9/iad0qWDrkriQIFz4GZmwBAg2znXL+z4Wc65r0Pftga+ik6JIinsiy/8zTkbNsCbb0KHDkFXJHEkkht5GgKZwGIzWxA69hBwk5mdDewFVgK3RqVCkVQ1ahR06QInneQvXJ57btAVSZyJZBXKTCCv+3EnFX05IkJuLvz97/DUU36p4NixcMopQVclcUi30ovEky1boGNHmDTJX7AcMACOPTboqiROKcBF4sVXX/n57m+/hUGD4FbNSkr+FOAi8eD99/3Iu1gx+PhjuPjioCuSBKDNrESC5Jyf677ySjjzTN98QeEtEdIIXCQoO3b4VSZvveW3gh0yBEqUCLoqSSAagYsEYeVK369y9Gg/An/zTYW3FJpG4CKxNmOG34xqzx5/V2XLlkFXJAlKI3CRWHHOry5p2tTfnDNnjsJbjogCXCQWdu/2ywJ79IDmzX14n3120FVJglOAi0TbunV+C9jBg+HBB2H8eL8drMgR0hy4SDTNmwdt2sCmTX5vk7/+NeiKJIloBC4SLW++6fcyOeoo369S4S1FTAEuUtRyc/2+3Z06Qb16/uacOnWCrkqSkKZQRIrS5s3+lvgPPvAXLPv3h7S0oKuSJKUAFykq2dl+M6oVK/wFy5tvDroiSXIKcJGi8N57fsrkuONg+nR/l6VIlGkOXORIOAdPPulH3n/+s5/vVnhLjGgELnK4fvkFOneGMWP86Pvll/0IXCRGFOAih2PFCj/q/vJL6NsXevUCy6vzoEj0KMBFCuuTT+CaayAnxzdiaNEi6IokRWkOXCRSzsELL0CzZnDyyTB3rsJbAqUAF4nErl1+WeDtt/sdBGfPhrPOCroqSXEKcJGCrF0LjRv7jjl//zu8+y6ccELQVYloDlwkX3PnQtu2/g7L0aOhXbugKxLZTyNwkUMZPhwuusjfCj9rlsJb4o4CXORgOTlw771w/fVwwQV+FF6rVtBVifyOplBEwv30k+8QP3Uq9OwJ/fppMyqJWwpwkX2WLPE353z/PbzyCtx0U9AVieSrwCkUM6toZtPNbKmZLTGzO0PH+5rZV2a2yMzeMbPSUa9WJFrGj4f69WH7dn+jjsJbEkAkc+A5QC/nXFWgPnCbmVUFpgLVnXM1gf8CD0avTJEo+eoryMz0bc+qVPGbUTVoEHRVIhEpMMCdc2ucc/NDX28DsoHTnXMfOudyQk+bDVSIXpkiRWzRIt/irGpVePttf9FyxgyooI+xJI5CrUIxs3SgDjDnoIe6AJMP8ZpuZpZlZlkbNmw4rCJFisy+JsO1asHkyfDAA35jqr59tZOgJJyIA9zMjgfGAXc557aGHe+Nn2YZkdfrnHODnXMZzrmM8uXLH2m9Iodn1ix/C3xGBnz6KfzjHz64n3wS9LmUBBXRKhQzS8OH9wjn3Nthx28ErgCaOudcVCoUOVzO+bB+7DGYNg3KlfOBfdttuhVekkKBAW5mBgwBsp1z/cKOtwDuBy5xzu2IXokiheQcfPghPP44zJwJp5wCzz4Lt94KJUsGXZ1IkYlkBN4QyAQWm9mC0LGHgAFAMWCqz3hmO+dujUaRIhFxDiZO9CPuuXP9BcmBA/2SQM1vSxIqMMCdczOBvFqNTCr6ckQOw969fiXJ44/DwoVQubLvCn/99VCsWNDViUSN9kKRxJWTAyNGQPXqfqOpX3+F116DZcv83t0Kb0lyCnBJPHv2wNChcM45cN11cNRRMHIkLF0KN9ygvUskZWgvFEkcu3b54H7qKVi5EurUgXHj/LruozQWkdSjAJf4t2MHvPwyPPMM/PgjnH8+vPiiX9etTvCSwhTgEr+2b4dBg/wSwPXr4eKL4fXXoWlTBbcICnCJR1u2+OV/zz/v9+e+9FLfi/Lii4OuTCSuKMAlfmzaBP/7vzBggA/xv/zFB3f9+kFXJhKXFOASvPXr4bnn4F//8tMmV13lg7tOnaArE4lrCnAJzurVfhfAwYNh506/vWvv3n5dt4gUSAEusbdyJTz9NAwZArm5fi33gw/C2WcHXZlIQlGAS+wsXw59+sCwYX4VSefO8Le/wRlnBF2ZSEJSgEv0ZWf7bVzffNPfJXnrrXD//VCxYtCViSQ0BbhEz6JFfoOpsWP9boB33w29esFppwVdmUhSUIBL0cvK8sE9fjyUKuXblt19tzrfiBQxBbgUnc8+88H9wQdQujQ88gjccQeUKRN0ZSJJSQEuR8Y5+OQT30Rh+nTftqxPH+jRQ23LRKJMAS6HxzmYMsWPuD/7DE491d+Mc8stalsmEiMKcCkc5+C99/yIOyvLryR54QXftqx48aCrE0kp2kRZIrN3L4wZA7VrQ+vWfpOpl1/2a7tvu03hLRIABbjkLycH3njD397evr1vqvD6675tWdeucOyxQVcokrIU4JK33bvh1Vd927LMTDj6aBg1CpYs8c2Cj9Hsm0jQ9F+hHGjnzt/aln3/PdSt6zu+t26ttmUicUYBLt6OHX5XwL59fduy+vV9N5zLL1f3G5E4pQBPddu2+aB+7jm/L/cll/jNppo0UXCLxDkFeKr6+Wfftqx/f7+i5LLLfBOFiy4KujIRiZACPNVs2uRDe8AA2LoVrrjCB/f55wddmYgUkgI8Vaxb91vbsl9+gauv9t1v1LZMJGEpwJNdeNuyXbt+a1tWrVrQlYnIESpwXZiZVTSz6Wa21MyWmNmdoePtQt/vNbOM6JcqhbJiBXTv7rvdvPCCD+7sbN9UQeEtkhQiGYHnAL2cc/PNrBQwz8ymAl8CVwH/jmaBUkjLl/vuN8OH+1UkXbr4tmWVKwddmYgUsQID3Dm3BlgT+nqbmWUDpzvnpgKYlprFh6VLfXCPHOlvb+/e3bctq1Ah6MpEJEoKNQduZulAHWBOIV7TDegGUKlSpcK8nURi4UK/peu4cVCiBNxzj29bduqpQVcmIlEW8b3RZnY8MA64yzm3NdLXOecGO+cynHMZ5dVSq+jMnetvb69d2+/L/eCDft67b1+Ft0iKiGgEbmZp+PAe4Zx7O7olSb4++8zvxT1lim9V9s9/wu23q22ZSAoqMMDNT3IPAbKdc/2iX5L8jnO+Xdljj/n2ZeXL+82mevTwTYNFJCVFMgJvCGQCi81sQejYQ0AxYCBQHnjfzBY455pHpcpU5ZxvEPz44zBrFpx2GvTrB926qW2ZiES0CmUmcKilJu8UbTkC+O43773ng3tf27IXX/RLAtX5RkRCtMFzPMnNhdGj/e3tbdr4TaZeecWv7e7RQ+EtIgdQgMeDnBx/40316v6OyV27/Jauy5b5ZsFqWyYieVCAB2n3bhgyBKpU8W3K0tLgrbd827LMTLUtE5F8KSGCsHOn7zf59NO+bdm558I770CrVmpbJiIRU4DH0sFtyy64AF56CVq0UPcbESk0BXgsbNvm9+F+7jnYsAEaNfJz3o0bK7hF5LApwKPp559955v+/WHzZmje3He/ufDCoCsTkSSgAI+GjRt9aA8c6NuWXXmlD+569YKuTESSiAK8KK1d66dJBg3y89372pbVrh10ZSKShBTgRWHVqt/alu3eDdde64O7atWgKxORJKYAPxIrVvhNpYYO9be/Z2b6bV3POivoykQkBSjAD8fXX0OfPn4lyVFH/da2LD096MpEJIUowAtjyRLftmzUKH97e48ecN99alsmIoFQgEdiwYLf2paVLOlblvXqBaecEnRlIpLCFOD5+fxzH9zvvQcnnOAvTN51F5QrF3RlIiIK8DzNnOm733z4IZQtC48+6tuWlS4ddGUiIvspwPdxDqZN88H96adw8sl+s6nu3dW2TETikgLcOZg82U+V/Oc/vm3Z88/7tmUlSgRdnYjIIaVugO/dCxMm+OCeNw8qVfIbTnXurM43IpIQUm/z6dxc3zShdm1o29ZvODVkiF/b3b27wltEEkbqBHhOjm9TVq2av9V9zx5/I85XX/kbcdS2TEQSTPJPoeze7YO7Tx/49luoWdM3Dr7qKjj66KCrExE5bMk7At+5E158Ef70J7j5Zr8c8N134YsvoF07hbeIJLzkG4H/8stvbcvWrIEGDfz3zZur+42IJJXkCfBt2/yIu18/37ascWMYMcK3L1Nwi0gSSvwA37zZd77Z17asRQvf/aZhw6ArExGJqsQN8I0b/Q03L7zg25a1auWD+7zzgq5MRCQmEi/A166FZ5/1bct+/RWuucZvMlWrVtCViYjEVIGrUMysoplNN7OlZrbEzO4MHS9rZlPN7OvQP8tEtdIffoA77oDKlf3Iu21b+PJLvyRQ4S0iKSiSZYQ5QC/nXFWgPnCbmVUFHgA+ds6dBXwc+j46HnsMzjzTj7o7doRly+CNN9RzUkRSWoEB7pxb45ybH/p6G5ANnA60Bl4PPe11oE2UavStym66yd/uPmSIX9stIpLizDkX+ZPN0oEZQHXge+dc6dBxAzbv+/6g13QDugFUqlTp3JUrVx5x0SIiqcTM5jnnMg4+HvGdmGZ2PDAOuMs5tzX8Mef/FsjzbwLn3GDnXIZzLqN8+fKFLFtERA4logA3szR8eI9wzr0dOrzOzE4LPX4asD46JYqISF4iWYViwBAg2znXL+yhCcANoa9vAMYXfXkiInIokawDbwhkAovNbEHo2EPAU8BoM7sJWAm0j0qFIiKSpwID3Dk3EzjUZiJNi7YcERGJVPJuJysikuQU4CIiCUoBLiKSoAp1I88Rv5nZBvwFz8NRDthYhOUUFdVVOKqrcFRX4cRrXXBktf3ROfe7G2liGuBHwsyy8roTKWiqq3BUV+GorsKJ17ogOrVpCkVEJEEpwEVEElQiBfjgoAs4BNVVOKqrcFRX4cRrXRCF2hJmDlxERA6USCNwEREJowAXEUlQcRHgZtbCzJaZ2XIz+11rNjMrZmZvhR6fE2osse+xB0PHl5lZ8xjXdU+oV+giM/vYzP4Y9liumS0I/ZkQ47puNLMNYe/fNeyxG0J9TL82sxsOfm2U63o+rKb/mtnPYY9F5XyZ2atmtt7MvjzE42ZmA0I1LzKzumGPRfNcFVRXp1A9i81slpnVCntsRej4AjPLinFdjcxsS9jv6uGwx/L9/Ue5rvvCavoy9HkqG3osmucrz57BBz0nep8x51ygf4CjgW+AM4BjgYVA1YOe0wN4KfT1tcBboa+rhp5fDKgc+jlHx7CuxkCJ0Nfd99UV+n57gOfrRuCFPF5bFvg29M8yoa/LxKqug55/O/BqDM7XxUBd4MtDPN4SmIzfsK0+MCfa5yrCuhrsez/g8n11hb5fAZQL6Hw1AiYe6e+/qOs66LlXAtNidL5OA+qGvi4F/DeP/x6j9hmLhxF4PWC5c+5b59xuYBS+32a48P6bY4GmZmah46Occ7ucc98By0M/LyZ1OeemO+d2hL6dDVQoovc+orry0RyY6pz7yTm3GZgKtAiorg7AyCJ670Nyzs0AfsrnKa2BYc6bDZQ236AkmueqwLqcc7NC7wux+2xFcr4O5Ug+l0VdV0w+W5Bvz+BwUfuMxUOAnw78EPb9Kn5/AvY/xzmXA2wBTorwtdGsK9xN+L9l9yluZllmNtvM2hRRTYWp6+rQ/66NNbOKhXxtNOsiNNVUGZgWdjha56sgh6o7mueqsA7+bDngQzObZ77nbKxdYGYLzWyymVULHYuL82VmJfAhOC7scEzOl/mp3TrAnIMeitpnLJKGDlIAM7sOyAAuCTv8R+fcajM7A5hmZoudc9/EqKT3gJHOuV1mdgv+/16axOi9I3EtMNY5lxt2LMjzFbfMrDE+wC8MO3xh6FydDEw1s69CI9RYmI//XW03s5bAu8BZMXrvSFwJfOacCx+tR/18WT49g6MpHkbgq4GKYd9XCB3L8zlmdgxwIrApwtdGsy7MrBnQG2jlnNu177hzbnXon98Cn+D/Zo5JXc65TWG1vAKcG+lro1lXmGs56H9xo3i+CnKouqN5riJiZjXxv7/WzrlN+46Hnav1wDsU3bRhgZxzW51z20NfTwLSzKwccXC+QvL7bEXlfFnePYPDRe8zFo2J/UJeBDgGP3lfmd8uflQ76Dm3ceBFzNGhr6tx4EXMbym6i5iR1FUHf+HmrIOOlwGKhb4uB3xNEV3QibCu08K+bgvMdr9dNPkuVF+Z0NdlY1VX6HlV8BeVLBbnK/Qz0zn0Rbm/cOAFps+jfa4irKsS/ppOg4OOlwRKhX09C2gRw7pO3fe7wwfh96FzF9HvP1p1hR4/ET9PXjJW5yv07z4M6J/Pc6L2GSuyk3uEJ6El/urtN0Dv0LFH8aNagOLAmNAH+nPgjLDX9g69bhlweYzr+ghYBywI/ZkQOt4AWBz6EC8GbopxXX2AJaH3nw5UCXttl9B5XA50jmVdoe8fAZ466HVRO1/40dgaYA9+jvEm4Fbg1tDjBrwYqnkxkBGjc1VQXa8Am8M+W1mh42eEztPC0O+4d4zr6hn22ZpN2F8wef3+Y1VX6Dk34hc1hL8u2ufrQvwc+6Kw31XLWH3GdCu9iEiCioc5cBEROQwKcBGRBKUAFxFJUApwEZEEpQAXEUlQCnARkQSlABcRSVD/D4ODQGAfozwdAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_values = train(model,num_epochs=3,lr=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is: 27.12146422628952 %\n",
      "Test Loss: 0.2455\n"
     ]
    }
   ],
   "source": [
    "test_values = test(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "def get_next_logdir():\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%d_%b[%H-%M-%S]\")\n",
    "    multi_val_index = 1\n",
    "    logs_dir = OUT_DIR + \"logs/\"\n",
    "    dir_name = logs_dir + date_time\n",
    "    while os.path.exists(dir_name):\n",
    "        multi_val_index += 1\n",
    "        dir_name = \"\".join([logs_dir, date_time, \"(\", str(multi_val_index), \")\"])\n",
    "    return dir_name\n",
    "\n",
    "def get_model_code():\n",
    "    import inspect, sys\n",
    "    from IPython.core.magics.code import extract_symbols\n",
    "\n",
    "    def new_getfile(object, _old_getfile=inspect.getfile):\n",
    "        if not inspect.isclass(object):\n",
    "            return _old_getfile(object)\n",
    "\n",
    "        # Lookup by parent module (as in current inspect)\n",
    "        if hasattr(object, '__module__'):\n",
    "            object_ = sys.modules.get(object.__module__)\n",
    "            if hasattr(object_, '__file__'):\n",
    "                return object_.__file__\n",
    "\n",
    "        # If parent module is __main__, lookup by methods (NEW)\n",
    "        for name, member in inspect.getmembers(object):\n",
    "            if inspect.isfunction(member) and object.__qualname__ + '.' + member.__name__ == member.__qualname__:\n",
    "                return inspect.getfile(member)\n",
    "        else:\n",
    "            raise TypeError('Source for {!r} not found'.format(object))\n",
    "\n",
    "    inspect.getfile = new_getfile\n",
    "    obj = PoseClassifier\n",
    "    cell_code = \"\".join(inspect.linecache.getlines(new_getfile(obj)))\n",
    "    class_code = extract_symbols(cell_code, obj.__name__)[0][0]\n",
    "    return class_code\n",
    "\n",
    "def save_run(model_obj, train_dict = None, test_dict= None):\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    import numbers, json\n",
    "    dir_name = get_next_logdir()\n",
    "    model_path = os.path.join(dir_name, \"model.ckpt\")\n",
    "    model_json_path = os.path.join(dir_name, \"model_params.json\")\n",
    "    model_classcode_path = os.path.join(dir_name, \"model_class_code.txt\")\n",
    "    writer = SummaryWriter(log_dir=dir_name)\n",
    "    model_dict = { \"params\": {\"num_classes\": num_classes, \"num_epochs\": num_epochs, \"batch_size\": batch_size, \"learning_rate\": learning_rate, \"learning_rate_decay\": learning_rate_decay}}\n",
    "\n",
    "\n",
    "    print(\"Saving {} in {}\".format(\"model\", model_path), end=\" \")\n",
    "    torch.save(model_obj.state_dict(), model_path)\n",
    "    print(\"DONE\")\n",
    "\n",
    "    def save_log(value_dict):\n",
    "        for key,value in value_dict.items():\n",
    "            if isinstance(value, numbers.Number):\n",
    "                writer.add_scalar(key, value, 0)\n",
    "            else:\n",
    "                for e, e_value in enumerate(value):\n",
    "                    writer.add_scalar(key, e_value, e)\n",
    "\n",
    "    print(\"Saving {} in {}\".format(\"Logs (if any)\", dir_name), end=\" \")\n",
    "    if train_dict is not None: save_log(train_dict)\n",
    "    if test_dict is not None:save_log(test_dict)\n",
    "    writer.close()\n",
    "    print(\"DONE\")\n",
    "\n",
    "    print(\"Saving {} in {}\".format(\"parameters\", model_json_path), end=\" \")\n",
    "    with open(model_json_path, \"w\") as jf:\n",
    "        json.dump(model_dict, jf)\n",
    "    print(\"DONE\")\n",
    "\n",
    "    print(\"Saving {} in {}\".format(\"class code\", model_classcode_path), end=\" \")\n",
    "    with open(model_classcode_path, \"w\") as f:\n",
    "        f.write(get_model_code())\n",
    "    print(\"DONE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model in ./out/logs/12_Dec[18-42-18]/model.ckpt DONE\n",
      "Saving Logs (if any) in ./out/logs/12_Dec[18-42-18] DONE\n",
      "Saving parameters in ./out/logs/12_Dec[18-42-18]/model_params.json DONE\n",
      "Saving class code in ./out/logs/12_Dec[18-42-18]/model_class_code.txt DONE\n"
     ]
    }
   ],
   "source": [
    "save_run(model, train_values, test_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}