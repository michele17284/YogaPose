{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Load pretrained weights from url: https://github.com/yangsenius/TransPose/releases/download/Hub/tp_r_256x192_enc4_d256_h1024_mh8.pth\n",
      "Successfully loaded model  (on cpu) with pretrained weights!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/michele/.cache/torch/hub/yangsenius_TransPose_main\n",
      "/home/michele/.cache/torch/hub/yangsenius_TransPose_main/lib/models/transpose_r.py:333: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = temperature ** (2 * (dim_t // 2) / one_direction_feats)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")            #comment this line to run with GPU\n",
    "tpr = torch.hub.load('yangsenius/TransPose:main', 'tpr_a4_256x192', pretrained=True)\n",
    "#tph = torch.hub.load('yangsenius/TransPose:main', 'tph_a4_256x192', pretrained=True, device=device)\n",
    "\n",
    "\n",
    "#print(tph)\n",
    "DATASET_PATH = './dataset/'\n",
    "positions = os.listdir(DATASET_PATH)\n",
    "#print(os.listdir(DATASET_PATH+entries[0]))\n",
    "images = list()\n",
    "\n",
    "def add_margin(pil_img, top, right, bottom, left, color):\n",
    "    width, height = pil_img.size\n",
    "    new_width = width + right + left\n",
    "    new_height = height + top + bottom\n",
    "    result = Image.new(pil_img.mode, (new_width, new_height), color)\n",
    "    result.paste(pil_img, (left, top))\n",
    "    return result\n",
    "\n",
    "class YogaPoseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path, size=(256,192)):\n",
    "        self.data_path = dataset_path\n",
    "        # call to init the data\n",
    "        self.size = size\n",
    "        self._init_data()\n",
    "\n",
    "    def _init_data(self):\n",
    "        positions = os.listdir(self.data_path)\n",
    "        images = list()\n",
    "        labels = list()\n",
    "        for idx, position in enumerate(positions):\n",
    "            for file in os.listdir(DATASET_PATH + position):\n",
    "                if not file.endswith('.gif'):\n",
    "                    f = cv2.imread(DATASET_PATH + position + '/' + file,cv2.IMREAD_COLOR)\n",
    "\n",
    "                    #print(position + '/' + file)\n",
    "                    #print(f.shape)\n",
    "                    height,width, channels = f.shape\n",
    "                    if height > width:\n",
    "                        scale_percent = self.size[0]/height\n",
    "                        f = cv2.resize(f,(int(width*scale_percent),self.size[0]))\n",
    "                        if f.shape[1] > self.size[1]:\n",
    "                            scale_percent = self.size[1]/width\n",
    "                            f = cv2.resize(f,(self.size[1],int(height*scale_percent)))\n",
    "                    else:\n",
    "                        scale_percent = self.size[1]/width\n",
    "                        f = cv2.resize(f,(self.size[1],int(height*scale_percent)))\n",
    "                        if f.shape[0] > self.size[1]:\n",
    "                            scale_percent = self.size[0]/height\n",
    "                            f = cv2.resize(f,(int(width*scale_percent),self.size[0]))\n",
    "\n",
    "                    height,width, channels = f.shape\n",
    "                    #print(f.shape,\"after resize\")\n",
    "                    f = cv2.copyMakeBorder(f, self.size[0]-height, 0, self.size[1]-width, 0, cv2.BORDER_CONSTANT,value=0)\n",
    "                    #print(f.shape,\"after padding\")\n",
    "                    #if torch.FloatTensor(f.getdata()).size()[1] != 3: f.show()\n",
    "                    data = torch.reshape(torch.FloatTensor(f).to(device),(3,self.size[0],self.size[1]))\n",
    "                    #print(data.shape)\n",
    "                    #print(data.size())\n",
    "                    ##images.append(data)\n",
    "                    ##labels.append(torch.tensor(idx))\n",
    "                    images.append((idx,data))\n",
    "\n",
    "\n",
    "        #print(images)\n",
    "        ##images = torch.stack(images)\n",
    "        ##labels = torch.stack(labels)\n",
    "        #print(labels)\n",
    "        #print(images.size())\n",
    "        ##mask = np.arange(labels.size()[0])\n",
    "        np.random.shuffle(images)\n",
    "        self.images = images\n",
    "        #print(type(images),type(images[0]))\n",
    "        ##self.images = images[mask]\n",
    "        ##self.labels = labels[mask]\n",
    "        #print(self.labels.size())\n",
    "        #print(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns the number of samples in our dataset\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def getData(self):\n",
    "        return self.images\n",
    "\n",
    "    #def getY(self):\n",
    "    #    return self.labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # returns the idx-th sample\n",
    "        return self.images[idx]\n",
    "\n",
    "    def collate_fn(self,data):\n",
    "        #print(len(data),data)\n",
    "        #print(data[0].size())\n",
    "        #print(data[1].size())\n",
    "        #print('lwwwwwwwwwwwwwww',[x[0].size() for x in data])\n",
    "        #print(torch.cat([x[0] for x in data]).size(),data[0][0].size())\n",
    "        #print(torch.stack([x[1] for x in data]).size(),data[0][1],[x[1] for x in data])\n",
    "        Xs = torch.stack([x[1] for x in data])\n",
    "        print(Xs.size())\n",
    "        y = torch.stack([torch.tensor(x[0]) for x in data])\n",
    "        print(y.size())\n",
    "        return Xs,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: Ignoring incorrect cHRM white(.34575,.35855) r(.6485,.33088)g(.32121,.59787)b(.15589,.06604) when sRGB is also present\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = YogaPoseDataset(DATASET_PATH)\n",
    "split_position = int((len(dataset)//10)*7)\n",
    "trainset = dataset[:split_position]\n",
    "testset = dataset[split_position:]\n",
    "print(trainset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(92,\n tensor([[[  0.,   0.,   0.,  ..., 115., 118., 132.],\n          [160., 162., 173.,  ..., 255., 255., 255.],\n          [255., 255., 255.,  ..., 255., 255., 255.],\n          ...,\n          [ 35.,  33.,  32.,  ..., 255., 255., 255.],\n          [255., 255., 255.,  ..., 255., 255., 255.],\n          [  0.,   0.,   0.,  ...,  30.,  28.,  27.]],\n \n         [[ 33.,  31.,  30.,  ..., 255., 255., 255.],\n          [255., 255., 255.,  ..., 255., 255., 255.],\n          [  0.,   0.,   0.,  ...,  32.,  30.,  29.],\n          ...,\n          [ 72.,  89., 135.,  ..., 255., 255., 255.],\n          [  0.,   0.,   0.,  ...,  24.,  24.,  24.],\n          [ 22.,  21.,  20.,  ...,  39.,  51.,  90.]],\n \n         [[ 52.,  67., 110.,  ..., 255., 255., 255.],\n          [  0.,   0.,   0.,  ...,  24.,  24.,  24.],\n          [ 21.,  21.,  21.,  ...,  31.,  42.,  74.],\n          ...,\n          [  0.,   0.,   0.,  ..., 244., 246., 246.],\n          [243., 245., 245.,  ..., 236., 237., 235.],\n          [236., 237., 235.,  ..., 254., 250., 249.]]]))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class PoseClassifier(nn.Module):\n",
    "    def __init__(self, n_class, fine_tune=False, pretrained=True):\n",
    "        super(PoseClassifier, self).__init__()\n",
    "\n",
    "        self.tph = torch.hub.load('yangsenius/TransPose:main', 'tph_a4_256x192', pretrained=True, device=device)\n",
    "        self.fc1 = nn.Linear(1088,1000).to(device)\n",
    "        self.fc2 = nn.Linear(1000,n_class).to(device)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.to(device)\n",
    "        print(x.size(),\"INPUT\")\n",
    "        out = self.tph(x)\n",
    "        print(out.size())\n",
    "        out = torch.einsum(\"abcd -> abc\",out)\n",
    "        print(out.size())\n",
    "        out = torch.reshape(out,(out.size(0),-1))\n",
    "        print(out.size())\n",
    "        out = self.fc1(out)\n",
    "        #m = nn.BatchNorm1d(1000,device=device)\n",
    "        #out = m(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Load pretrained weights from url: https://github.com/yangsenius/TransPose/releases/download/Hub/tp_h_48_256x192_enc4_d96_h192_mh1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/michele/.cache/torch/hub/yangsenius_TransPose_main\n",
      "/home/michele/.cache/torch/hub/yangsenius_TransPose_main/lib/models/transpose_h.py:514: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = temperature ** (2 * (dim_t // 2) / one_direction_feats)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model  (on cpu) with pretrained weights!\n"
     ]
    }
   ],
   "source": [
    "num_classes = 107\n",
    "model = PoseClassifier(n_class=num_classes)\n",
    "num_epochs = 30\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "learning_rate_decay = 0.99\n",
    "params_to_update = model.parameters()\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "fine_tune=True\n",
    "if fine_tune:\n",
    "    params_to_update = []\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    for param in model.tph.parameters():\n",
    "        param.requires_grad = False\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad == True:\n",
    "            params_to_update.append(p)\n",
    "else:\n",
    "    params_to_update = model.parameters()\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset,batch_size=batch_size,shuffle=False,collate_fn=dataset.collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size,shuffle=False,collate_fn=dataset.collate_fn)\n",
    "# Train the model\n",
    "lr = learning_rate\n",
    "total_step = len(train_loader)\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "best_accuracy = None\n",
    "accuracy_val = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 256, 192])\n",
      "torch.Size([16])\n",
      "tensor([[[[  0.,   0.,   0.,  ..., 115., 118., 132.],\n",
      "          [160., 162., 173.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          ...,\n",
      "          [ 35.,  33.,  32.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [  0.,   0.,   0.,  ...,  30.,  28.,  27.]],\n",
      "\n",
      "         [[ 33.,  31.,  30.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "          [  0.,   0.,   0.,  ...,  32.,  30.,  29.],\n",
      "          ...,\n",
      "          [ 72.,  89., 135.,  ..., 255., 255., 255.],\n",
      "          [  0.,   0.,   0.,  ...,  24.,  24.,  24.],\n",
      "          [ 22.,  21.,  20.,  ...,  39.,  51.,  90.]],\n",
      "\n",
      "         [[ 52.,  67., 110.,  ..., 255., 255., 255.],\n",
      "          [  0.,   0.,   0.,  ...,  24.,  24.,  24.],\n",
      "          [ 21.,  21.,  21.,  ...,  31.,  42.,  74.],\n",
      "          ...,\n",
      "          [  0.,   0.,   0.,  ..., 244., 246., 246.],\n",
      "          [243., 245., 245.,  ..., 236., 237., 235.],\n",
      "          [236., 237., 235.,  ..., 254., 250., 249.]]],\n",
      "\n",
      "\n",
      "        [[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          ...,\n",
      "          [142., 126., 110.,  ..., 148., 132., 117.],\n",
      "          [153., 137., 123.,  ..., 168., 160., 141.],\n",
      "          [103.,  79.,  64.,  ..., 141., 125., 108.]],\n",
      "\n",
      "         [[143., 127., 111.,  ..., 148., 133., 116.],\n",
      "          [151., 135., 120.,  ..., 169., 162., 142.],\n",
      "          [108.,  85.,  69.,  ..., 140., 124., 107.],\n",
      "          ...,\n",
      "          [ 76., 100., 151.,  ..., 181., 175., 161.],\n",
      "          [128.,  96.,  57.,  ..., 142., 116.,  78.],\n",
      "          [143., 117.,  80.,  ...,  57.,  75., 121.]],\n",
      "\n",
      "         [[ 74.,  98., 150.,  ..., 182., 179., 165.],\n",
      "          [132., 105.,  68.,  ..., 139., 116.,  79.],\n",
      "          [141., 119.,  87.,  ...,  60.,  80., 124.],\n",
      "          ...,\n",
      "          [ 84.,  69.,   9.,  ..., 131.,  92.,   1.],\n",
      "          [131.,  92.,   2.,  ..., 141., 110.,   8.],\n",
      "          [142., 111.,  10.,  ..., 148., 135.,  27.]]],\n",
      "\n",
      "\n",
      "        [[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          ...,\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "         [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          ...,\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "         [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          ...,\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          ...,\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "         [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          ...,\n",
      "          [220., 216., 205.,  ..., 226., 229., 232.],\n",
      "          [221., 224., 227.,  ..., 241., 241., 241.],\n",
      "          [241., 241., 241.,  ..., 176., 189., 217.]],\n",
      "\n",
      "         [[164., 182., 223.,  ..., 227., 230., 233.],\n",
      "          [227., 229., 231.,  ..., 241., 241., 240.],\n",
      "          [241., 241., 241.,  ..., 150., 175., 221.],\n",
      "          ...,\n",
      "          [230., 215., 206.,  ...,  38.,  39.,  41.],\n",
      "          [ 37.,  39.,  40.,  ..., 221., 216., 213.],\n",
      "          [221., 216., 213.,  ...,  48.,  47.,  46.]]],\n",
      "\n",
      "\n",
      "        [[[  0.,   0.,   0.,  ...,  67., 138., 175.],\n",
      "          [ 70., 140., 178.,  ...,  77., 173., 227.],\n",
      "          [ 77., 173., 227.,  ...,  65., 156., 211.],\n",
      "          ...,\n",
      "          [ 53.,  43.,  35.,  ...,  34.,  28.,  29.],\n",
      "          [ 34.,  28.,  29.,  ...,  88., 185., 235.],\n",
      "          [  0.,   0.,   0.,  ...,  39.,  34.,  31.]],\n",
      "\n",
      "         [[ 45.,  41.,  36.,  ...,  34.,  28.,  29.],\n",
      "          [ 34.,  28.,  29.,  ...,  88., 185., 235.],\n",
      "          [  0.,   0.,   0.,  ...,  30.,  27.,  27.],\n",
      "          ...,\n",
      "          [ 96.,  70.,  53.,  ..., 138., 175., 210.],\n",
      "          [  0.,   0.,   0.,  ...,  33.,  62., 137.],\n",
      "          [ 30.,  53., 117.,  ...,  64.,  47.,  45.]],\n",
      "\n",
      "         [[ 73.,  60.,  56.,  ..., 132., 164., 200.],\n",
      "          [  0.,   0.,   0.,  ...,  39.,  67., 143.],\n",
      "          [ 36.,  60., 126.,  ...,  77.,  43.,  44.],\n",
      "          ...,\n",
      "          [  0.,   0.,   0.,  ..., 103., 164., 220.],\n",
      "          [103., 164., 220.,  ...,  82., 130., 187.],\n",
      "          [ 78., 128., 184.,  ...,  71., 131., 191.]]],\n",
      "\n",
      "\n",
      "        [[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          ...,\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "         [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          ...,\n",
      "          [ 38.,  64., 100.,  ..., 198., 198., 198.],\n",
      "          [198., 198., 198.,  ..., 199., 199., 199.],\n",
      "          [199., 199., 199.,  ...,  75.,  99., 135.]],\n",
      "\n",
      "         [[ 63.,  89., 125.,  ..., 198., 198., 198.],\n",
      "          [197., 197., 197.,  ..., 199., 199., 199.],\n",
      "          [199., 199., 199.,  ..., 107., 133., 169.],\n",
      "          ...,\n",
      "          [236., 232., 232.,  ..., 241., 239., 237.],\n",
      "          [240., 238., 237.,  ..., 226., 223., 223.],\n",
      "          [225., 223., 221.,  ..., 221., 218., 219.]]]]) tensor([92, 89, 74, 74, 21, 75, 12, 21, 90, 66, 42, 32, 53, 41, 84, 82])\n"
     ]
    }
   ],
   "source": [
    "for image,label in train_loader:\n",
    "    print(image,label)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "Epoch [1/30], Step [100/263], Loss: 4.4999\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "Epoch [1/30], Step [200/263], Loss: 4.6639\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([16, 3, 256, 192]) INPUT\n",
      "torch.Size([16, 17, 64, 48])\n",
      "torch.Size([16, 17, 64])\n",
      "torch.Size([16, 1088])\n",
      "torch.Size([1, 3, 256, 192]) INPUT\n",
      "torch.Size([1, 17, 64, 48])\n",
      "torch.Size([1, 17, 64])\n",
      "torch.Size([1, 1088])\n",
      "torch.Size([16]) INPUT\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [64, 3, 3, 3], but got 1-dimensional input of size [16] instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_28046/37637588.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     56\u001B[0m             \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m             \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     59\u001B[0m             \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredicted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/AML/Project/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_28046/2570924094.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"INPUT\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meinsum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"abcd -> abc\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/AML/Project/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.cache/torch/hub/yangsenius_TransPose_main/lib/models/transpose_h.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    617\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    618\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 619\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    620\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbn1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    621\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/AML/Project/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/AML/Project/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 446\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    447\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/AML/Project/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    440\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    441\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[0;32m--> 442\u001B[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0m\u001B[1;32m    443\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected 4-dimensional input for 4-dimensional weight [64, 3, 3, 3], but got 1-dimensional input of size [16] instead"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "params_to_update = model.parameters()\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset,batch_size=batch_size,shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size,shuffle=False)\n",
    "# Train the model\n",
    "lr = learning_rate\n",
    "total_step = len(train_loader)\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "best_accuracy = None\n",
    "accuracy_val = []\n",
    "#best_model = type(model)(num_classes, fine_tune, pretrained) # get a new instance\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_iter = 0\n",
    "    for i, (labels, images) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_iter += loss.item()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    loss_train.append(loss_iter/(len(train_loader)*batch_size))\n",
    "\n",
    "\n",
    "    # Code to update the lr\n",
    "    lr *= learning_rate_decay\n",
    "    update_lr(optimizer, lr)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loss_iter = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_iter += loss.item()\n",
    "\n",
    "        loss_val.append(loss_iter/(len(val_loader)*batch_size))\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        accuracy_val.append(accuracy)\n",
    "\n",
    "        print('Validataion accuracy is: {} %'.format(accuracy))\n",
    "        #################################################################################\n",
    "        # TODO: Q2.b Use the early stopping mechanism from previous questions to save   #\n",
    "        # the model with the best validation accuracy so-far (use best_model).          #\n",
    "        #################################################################################\n",
    "\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        early_stop = False\n",
    "        patience = 3\n",
    "        if epoch > patience - 1:\n",
    "            for j in range(patience - 1):\n",
    "                if max(accuracy_val) > list(reversed(accuracy_val))[j]:\n",
    "                    if \"not_improving_epochs\" in locals(): not_improving_epochs += 1\n",
    "                    else: not_improving_epochs = 1\n",
    "                    print('Not saving the model')\n",
    "                else:\n",
    "                    not_improving_epochs = 0\n",
    "                    best_model = model\n",
    "                    print(\"Saving the model\")\n",
    "                    break\n",
    "                if not_improving_epochs >= patience:\n",
    "                    early_stop = True\n",
    "                    print('Early stopping')\n",
    "                    break\n",
    "                break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}