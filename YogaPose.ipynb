{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")            #comment this line to run with GPU\n",
    "#tpr = torch.hub.load('yangsenius/TransPose:main', 'tpr_a4_256x192', pretrained=True)\n",
    "#tph = torch.hub.load('yangsenius/TransPose:main', 'tph_a4_256x192', pretrained=True, device=device)\n",
    "\n",
    "\n",
    "#print(tph)\n",
    "DATASET_PATH = './dataset/'\n",
    "positions = os.listdir(DATASET_PATH)\n",
    "#print(os.listdir(DATASET_PATH+entries[0]))\n",
    "images = list()\n",
    "\n",
    "def add_margin(pil_img, top, right, bottom, left, color):\n",
    "    width, height = pil_img.size\n",
    "    new_width = width + right + left\n",
    "    new_height = height + top + bottom\n",
    "    result = Image.new(pil_img.mode, (new_width, new_height), color)\n",
    "    result.paste(pil_img, (left, top))\n",
    "    return result\n",
    "\n",
    "class YogaPoseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path, size=(256,192)):\n",
    "        self.data_path = dataset_path\n",
    "        # call to init the data\n",
    "        self.size = size\n",
    "        self._init_data()\n",
    "\n",
    "    def _init_data(self):\n",
    "        positions = os.listdir(self.data_path)\n",
    "        images = list()\n",
    "        labels = list()\n",
    "        for idx, position in enumerate(positions):\n",
    "            for file in os.listdir(DATASET_PATH + position):\n",
    "                if not file.endswith('.gif'):\n",
    "                    f = cv2.imread(DATASET_PATH + position + '/' + file,cv2.IMREAD_COLOR)\n",
    "\n",
    "                    #print(position + '/' + file)\n",
    "                    #print(f.shape)\n",
    "                    height,width, channels = f.shape\n",
    "                    if height > width:\n",
    "                        scale_percent = self.size[0]/height\n",
    "                        f = cv2.resize(f,(int(width*scale_percent),self.size[0]))\n",
    "                        if f.shape[1] > self.size[1]:\n",
    "                            scale_percent = self.size[1]/width\n",
    "                            f = cv2.resize(f,(self.size[1],int(height*scale_percent)))\n",
    "                    else:\n",
    "                        scale_percent = self.size[1]/width\n",
    "                        f = cv2.resize(f,(self.size[1],int(height*scale_percent)))\n",
    "                        if f.shape[0] > self.size[1]:\n",
    "                            scale_percent = self.size[0]/height\n",
    "                            f = cv2.resize(f,(int(width*scale_percent),self.size[0]))\n",
    "\n",
    "                    height,width, channels = f.shape\n",
    "                    #print(f.shape,\"after resize\")\n",
    "                    f = cv2.copyMakeBorder(f, self.size[0]-height, 0, self.size[1]-width, 0, cv2.BORDER_CONSTANT,value=0)\n",
    "                    #print(f.shape,\"after padding\")\n",
    "                    #if torch.FloatTensor(f.getdata()).size()[1] != 3: f.show()\n",
    "                    data = torch.reshape(torch.FloatTensor(f).to(device),(3,self.size[0],self.size[1]))\n",
    "                    #print(data.shape)\n",
    "                    #print(data.size())\n",
    "                    ##images.append(data)\n",
    "                    ##labels.append(torch.tensor(idx))\n",
    "                    images.append((idx,data))\n",
    "\n",
    "\n",
    "        #print(images)\n",
    "        ##images = torch.stack(images)\n",
    "        ##labels = torch.stack(labels)\n",
    "        #print(labels)\n",
    "        #print(images.size())\n",
    "        ##mask = np.arange(labels.size()[0])\n",
    "        np.random.shuffle(images)\n",
    "        self.images = images\n",
    "        #print(type(images),type(images[0]))\n",
    "        ##self.images = images[mask]\n",
    "        ##self.labels = labels[mask]\n",
    "        #print(self.labels.size())\n",
    "        #print(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        # returns the number of samples in our dataset\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def getData(self):\n",
    "        return self.images\n",
    "\n",
    "    #def getY(self):\n",
    "    #    return self.labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # returns the idx-th sample\n",
    "        return self.images[idx]\n",
    "\n",
    "    def collate_fn(self,data):\n",
    "        #print(len(data),data)\n",
    "        #print(data[0].size())\n",
    "        #print(data[1].size())\n",
    "        #print('lwwwwwwwwwwwwwww',[x[0].size() for x in data])\n",
    "        #print(torch.cat([x[0] for x in data]).size(),data[0][0].size())\n",
    "        #print(torch.stack([x[1] for x in data]).size(),data[0][1],[x[1] for x in data])\n",
    "        Xs = torch.stack([x[1] for x in data])\n",
    "        #print(Xs.size())\n",
    "        y = torch.stack([torch.tensor(x[0]) for x in data])\n",
    "        #print(y.size())\n",
    "        return Xs,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: Ignoring incorrect cHRM white(.34575,.35855) r(.6485,.33088)g(.32121,.59787)b(.15589,.06604) when sRGB is also present\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [255., 254., 253.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 237., 229., 230.],\n",
      "         [255., 255., 255.,  ..., 255., 253., 251.]],\n",
      "\n",
      "        [[255., 254., 253.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 237., 229., 230.],\n",
      "         [255., 255., 255.,  ..., 255., 253., 252.],\n",
      "         ...,\n",
      "         [247., 235., 233.,  ..., 227., 214., 216.],\n",
      "         [241., 228., 230.,  ...,  72., 152.,  94.],\n",
      "         [ 55., 132.,  72.,  ..., 247., 235., 233.]],\n",
      "\n",
      "        [[247., 235., 233.,  ..., 227., 214., 216.],\n",
      "         [241., 228., 230.,  ...,  48., 106.,  65.],\n",
      "         [ 37.,  92.,  52.,  ..., 247., 235., 233.],\n",
      "         ...,\n",
      "         [140., 103., 200.,  ..., 152., 120., 205.],\n",
      "         [152., 120., 204.,  ..., 151., 125., 217.],\n",
      "         [151., 125., 217.,  ...,  90.,  75., 139.]]])), (106, tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [181., 229., 254.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 253., 250., 241.],\n",
      "         [254., 252., 241.,  ..., 129., 184., 246.]],\n",
      "\n",
      "        [[142., 203., 252.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ...,  78.,  73.,  68.],\n",
      "         [167., 136., 144.,  ..., 128., 188., 236.],\n",
      "         ...,\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 224., 233., 237.],\n",
      "         [225., 232., 235.,  ..., 255., 255., 255.]]])), (35, tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ..., 109., 103.,  78.],\n",
      "         [ 98.,  95.,  83.,  ..., 113., 105.,  76.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ..., 135., 158., 220.],\n",
      "         [135., 158., 220.,  ..., 113., 105.,  76.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        [[  0.,   0.,   0.,  ..., 135., 158., 220.],\n",
      "         [134., 157., 219.,  ..., 113., 105.,  76.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [246., 246., 246.,  ..., 113., 105.,  76.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ..., 247., 247., 247.]],\n",
      "\n",
      "        [[246., 246., 246.,  ..., 113., 105.,  76.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ..., 247., 247., 247.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ..., 113., 105.,  76.],\n",
      "         [113., 105.,  76.,  ..., 113., 105.,  76.]]])), (51, tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.]]])), (91, tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ..., 108., 146., 197.],\n",
      "         [109., 148., 200.,  ..., 255., 255., 255.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        [[  0.,   0.,   0.,  ..., 102., 140., 192.],\n",
      "         [100., 139., 192.,  ..., 255., 255., 255.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [ 33.,  33.,  21.,  ..., 255., 255., 255.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,  32.,  33.,  21.]],\n",
      "\n",
      "        [[ 33.,  33.,  21.,  ..., 255., 255., 255.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,  32.,  33.,  21.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ..., 255., 255., 255.],\n",
      "         [255., 255., 255.,  ..., 255., 255., 255.]]])), (10, tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ..., 233., 234., 238.],\n",
      "         [233., 234., 238.,  ..., 233., 234., 238.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ..., 244., 244., 244.],\n",
      "         [244., 244., 244.,  ..., 241., 243., 243.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        [[  0.,   0.,   0.,  ..., 242., 244., 244.],\n",
      "         [242., 244., 244.,  ..., 239., 244., 243.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [195., 197., 198.,  ..., 193., 198., 197.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ..., 195., 197., 198.]],\n",
      "\n",
      "        [[195., 197., 198.,  ..., 193., 198., 197.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ..., 205., 210., 209.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ..., 231., 234., 238.],\n",
      "         [231., 234., 238.,  ..., 228., 232., 237.]]])), (11, tensor([[[  0.,   0.,   0.,  ...,  71., 100., 112.],\n",
      "         [ 75., 102., 117.,  ...,  61.,  97., 109.],\n",
      "         [ 54.,  82.,  96.,  ...,  50.,  71.,  86.],\n",
      "         ...,\n",
      "         [ 42.,  55.,  68.,  ...,  83.,  88., 111.],\n",
      "         [ 72.,  79., 104.,  ...,  55., 120., 117.],\n",
      "         [  0.,   0.,   0.,  ...,  35.,  45.,  59.]],\n",
      "\n",
      "        [[ 58.,  60.,  76.,  ...,  79.,  85., 108.],\n",
      "         [ 66.,  73.,  98.,  ...,  58., 121., 120.],\n",
      "         [  0.,   0.,   0.,  ...,  34.,  55.,  67.],\n",
      "         ...,\n",
      "         [107., 109., 168.,  ...,   1.,  38.,  22.],\n",
      "         [  0.,   0.,   0.,  ...,  28.,  46.,  55.],\n",
      "         [ 18.,  43.,  51.,  ..., 110., 114., 178.]],\n",
      "\n",
      "        [[132., 133., 195.,  ...,   0.,  30.,  16.],\n",
      "         [  0.,   0.,   0.,  ...,  12.,  29.,  39.],\n",
      "         [ 35.,  46.,  58.,  ..., 106., 110., 174.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ..., 146., 128., 113.],\n",
      "         [144., 130., 113.,  ..., 110.,   2.,   1.],\n",
      "         [111.,   1.,   0.,  ..., 118.,  10.,   0.]]])), (20, tensor([[[  0.,   0.,   0.,  ..., 192., 217., 238.],\n",
      "         [199., 216., 237.,  ..., 193., 212., 235.],\n",
      "         [193., 211., 234.,  ..., 194., 211., 228.],\n",
      "         ...,\n",
      "         [ 17.,  14.,  17.,  ..., 123., 129., 157.],\n",
      "         [111., 132., 159.,  ..., 187., 206., 225.],\n",
      "         [  0.,   0.,   0.,  ...,  16.,  13.,  16.]],\n",
      "\n",
      "        [[ 16.,  13.,  16.,  ..., 120., 130., 158.],\n",
      "         [114., 133., 160.,  ..., 187., 206., 225.],\n",
      "         [  0.,   0.,   0.,  ...,  16.,  13.,  16.],\n",
      "         ...,\n",
      "         [186., 194., 211.,  ..., 180., 193., 212.],\n",
      "         [  0.,   0.,   0.,  ...,  15.,  12.,  15.],\n",
      "         [ 16.,  11.,  13.,  ..., 186., 189., 207.]],\n",
      "\n",
      "        [[182., 191., 209.,  ..., 179., 192., 211.],\n",
      "         [  0.,   0.,   0.,  ...,  12.,  11.,  15.],\n",
      "         [ 13.,  12.,  15.,  ..., 185., 190., 211.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ..., 127.,  88.,  66.],\n",
      "         [129.,  87.,  64.,  ..., 140.,  93.,  69.],\n",
      "         [140.,  96.,  75.,  ..., 147., 109.,  73.]]])), (71, tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [247., 245., 235.,  ..., 228., 226., 225.],\n",
      "         [206., 214., 203.,  ..., 180., 183., 181.],\n",
      "         [228., 230., 229.,  ..., 239., 243., 232.]],\n",
      "\n",
      "        [[247., 245., 235.,  ..., 228., 226., 225.],\n",
      "         [205., 213., 202.,  ...,  81.,  90., 142.],\n",
      "         [133., 146., 208.,  ..., 219., 221., 211.],\n",
      "         ...,\n",
      "         [206., 220., 226.,  ..., 223., 146.,  84.],\n",
      "         [222., 145.,  83.,  ..., 225., 151.,  97.],\n",
      "         [225., 150.,  98.,  ..., 218., 225., 228.]]])), (70, tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         ...,\n",
      "         [ 41.,  31.,  25.,  ...,   3.,   3.,   3.],\n",
      "         [  2.,   2.,   2.,  ...,  71.,  55.,  39.],\n",
      "         [ 32.,  23.,  14.,  ...,  41.,  31.,  24.]],\n",
      "\n",
      "        [[ 40.,  30.,  24.,  ...,   6.,   6.,   6.],\n",
      "         [  4.,   4.,   4.,  ...,  67.,  52.,  37.],\n",
      "         [ 32.,  24.,  15.,  ...,  41.,  31.,  23.],\n",
      "         ...,\n",
      "         [ 53.,  38.,  22.,  ...,  67.,  53.,  37.],\n",
      "         [165., 159., 157.,  ...,  26.,  28.,  34.],\n",
      "         [ 33.,  36.,  41.,  ...,  53.,  38.,  22.]],\n",
      "\n",
      "        [[ 54.,  39.,  23.,  ...,  66.,  52.,  36.],\n",
      "         [ 43.,  39.,  37.,  ...,  28.,  29.,  35.],\n",
      "         [ 37.,  40.,  45.,  ...,  54.,  39.,  23.],\n",
      "         ...,\n",
      "         [ 57.,  61.,  65.,  ...,  62.,  67.,  76.],\n",
      "         [ 61.,  67.,  75.,  ...,  93.,  94.,  99.],\n",
      "         [171., 174., 178.,  ...,  58.,  66.,  79.]]]))]\n"
     ]
    }
   ],
   "source": [
    "dataset = YogaPoseDataset(DATASET_PATH)\n",
    "split_position = int((len(dataset)//10)*7)\n",
    "trainset = dataset[:split_position]\n",
    "testset = dataset[split_position:]\n",
    "trainset = dataset[:10]\n",
    "print(trainset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(30,\n tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n          ...,\n          [255., 254., 253.,  ..., 255., 255., 255.],\n          [255., 255., 255.,  ..., 237., 229., 230.],\n          [255., 255., 255.,  ..., 255., 253., 251.]],\n \n         [[255., 254., 253.,  ..., 255., 255., 255.],\n          [255., 255., 255.,  ..., 237., 229., 230.],\n          [255., 255., 255.,  ..., 255., 253., 252.],\n          ...,\n          [247., 235., 233.,  ..., 227., 214., 216.],\n          [241., 228., 230.,  ...,  72., 152.,  94.],\n          [ 55., 132.,  72.,  ..., 247., 235., 233.]],\n \n         [[247., 235., 233.,  ..., 227., 214., 216.],\n          [241., 228., 230.,  ...,  48., 106.,  65.],\n          [ 37.,  92.,  52.,  ..., 247., 235., 233.],\n          ...,\n          [140., 103., 200.,  ..., 152., 120., 205.],\n          [152., 120., 204.,  ..., 151., 125., 217.],\n          [151., 125., 217.,  ...,  90.,  75., 139.]]]))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class PoseClassifier(nn.Module):\n",
    "    def __init__(self, n_class, fine_tune=False, pretrained=True):\n",
    "        super(PoseClassifier, self).__init__()\n",
    "\n",
    "        self.tph = torch.hub.load('yangsenius/TransPose:main', 'tph_a4_256x192', pretrained=True, device=device)\n",
    "        self.fc1 = nn.Linear(52224,10000).to(device)\n",
    "        self.fc2 = nn.Linear(10000,1000).to(device)\n",
    "        self.fc3 = nn.Linear(1000,n_class).to(device)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.to(device)\n",
    "        #print(x.size(),\"INPUT\")\n",
    "        out = self.tph(x)\n",
    "        #out = self.relu(out)\n",
    "        #print(out.size(), \"AFTER TPH\")\n",
    "        #out = torch.einsum(\"abcd -> abc\",out)\n",
    "        #print(out.size())\n",
    "        out = torch.reshape(out,(out.size(0),-1))\n",
    "        #print(out.size())\n",
    "        out = self.fc1(out)\n",
    "        #m = nn.BatchNorm1d(1000,device=device)\n",
    "        #out = m(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return torch.softmax(out,dim=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Load pretrained weights from url: https://github.com/yangsenius/TransPose/releases/download/Hub/tp_h_48_256x192_enc4_d96_h192_mh1.pth\n",
      "Successfully loaded model  (on cpu) with pretrained weights!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/michele/.cache/torch/hub/yangsenius_TransPose_main\n"
     ]
    }
   ],
   "source": [
    "num_classes = 107\n",
    "model = PoseClassifier(n_class=num_classes)\n",
    "num_epochs = 50\n",
    "batch_size = 1\n",
    "learning_rate = 1e-4\n",
    "learning_rate_decay = 0.99\n",
    "params_to_update = model.parameters()\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "fine_tune=True\n",
    "if fine_tune:\n",
    "    params_to_update = []\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    for param in model.tph.parameters():\n",
    "        param.requires_grad = False\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad == True:\n",
    "            params_to_update.append(p)\n",
    "else:\n",
    "    params_to_update = model.parameters()\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset,batch_size=batch_size,shuffle=False,collate_fn=dataset.collate_fn)\n",
    "#val_loader = torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size,shuffle=False,collate_fn=dataset.collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=trainset,batch_size=batch_size,shuffle=False,collate_fn=dataset.collate_fn)\n",
    "# Train the model\n",
    "lr = learning_rate\n",
    "total_step = len(train_loader)\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "best_accuracy = None\n",
    "accuracy_val = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 192]) torch.Size([1]) tensor([[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "          ...,\n",
      "          [255., 254., 253.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 237., 229., 230.],\n",
      "          [255., 255., 255.,  ..., 255., 253., 251.]],\n",
      "\n",
      "         [[255., 254., 253.,  ..., 255., 255., 255.],\n",
      "          [255., 255., 255.,  ..., 237., 229., 230.],\n",
      "          [255., 255., 255.,  ..., 255., 253., 252.],\n",
      "          ...,\n",
      "          [247., 235., 233.,  ..., 227., 214., 216.],\n",
      "          [241., 228., 230.,  ...,  72., 152.,  94.],\n",
      "          [ 55., 132.,  72.,  ..., 247., 235., 233.]],\n",
      "\n",
      "         [[247., 235., 233.,  ..., 227., 214., 216.],\n",
      "          [241., 228., 230.,  ...,  48., 106.,  65.],\n",
      "          [ 37.,  92.,  52.,  ..., 247., 235., 233.],\n",
      "          ...,\n",
      "          [140., 103., 200.,  ..., 152., 120., 205.],\n",
      "          [152., 120., 204.,  ..., 151., 125., 217.],\n",
      "          [151., 125., 217.,  ...,  90.,  75., 139.]]]]) tensor([30])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for image,label in train_loader:\n",
    "    print(image.size(),label.size(),image,label)\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion accuracy is: 40.0 %\n",
      "Validataion accuracy is: 20.0 %\n",
      "Validataion accuracy is: 20.0 %\n",
      "Validataion accuracy is: 20.0 %\n",
      "Not saving the model\n",
      "Validataion accuracy is: 20.0 %\n",
      "Not saving the model\n",
      "Validataion accuracy is: 30.0 %\n",
      "Not saving the model\n",
      "Early stopping\n",
      "Validataion accuracy is: 30.0 %\n",
      "Not saving the model\n",
      "Early stopping\n",
      "Validataion accuracy is: 30.0 %\n",
      "Not saving the model\n",
      "Early stopping\n",
      "Validataion accuracy is: 30.0 %\n",
      "Not saving the model\n",
      "Early stopping\n",
      "Validataion accuracy is: 40.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 50.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 40.0 %\n",
      "Not saving the model\n",
      "Validataion accuracy is: 50.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 40.0 %\n",
      "Not saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n",
      "Validataion accuracy is: 60.0 %\n",
      "Saving the model\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.to(device)\n",
    "params_to_update = model.parameters()\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
    "#train_loader = torch.utils.data.DataLoader(dataset=trainset,batch_size=batch_size,shuffle=False)\n",
    "#val_loader = torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size,shuffle=False)\n",
    "# Train the model\n",
    "lr = learning_rate\n",
    "total_step = len(train_loader)\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "best_accuracy = None\n",
    "accuracy_val = []\n",
    "#best_model = type(model)(num_classes, fine_tune, pretrained) # get a new instance\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_iter = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_iter += loss.item()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    loss_train.append(loss_iter/(len(train_loader)*batch_size))\n",
    "\n",
    "\n",
    "    # Code to update the lr\n",
    "    lr *= learning_rate_decay\n",
    "    update_lr(optimizer, lr)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loss_iter = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            #print(outputs)\n",
    "            #print(torch.sum(outputs[0]),torch.sum(outputs[1]))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            #print(\"PREDICTED\",predicted)\n",
    "            #print(\"LABELS\",labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_iter += loss.item()\n",
    "\n",
    "        loss_val.append(loss_iter/(len(val_loader)*batch_size))\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        accuracy_val.append(accuracy)\n",
    "\n",
    "        print('Validataion accuracy is: {} %'.format(accuracy))\n",
    "        #################################################################################\n",
    "        # TODO: Q2.b Use the early stopping mechanism from previous questions to save   #\n",
    "        # the model with the best validation accuracy so-far (use best_model).          #\n",
    "        #################################################################################\n",
    "\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        early_stop = False\n",
    "        patience = 3\n",
    "        if epoch > patience - 1:\n",
    "            for j in range(patience - 1):\n",
    "                if max(accuracy_val) > list(reversed(accuracy_val))[j]:\n",
    "                    if \"not_improving_epochs\" in locals(): not_improving_epochs += 1\n",
    "                    else: not_improving_epochs = 1\n",
    "                    print('Not saving the model')\n",
    "                else:\n",
    "                    not_improving_epochs = 0\n",
    "                    best_model = model\n",
    "                    print(\"Saving the model\")\n",
    "                    break\n",
    "                if not_improving_epochs >= patience:\n",
    "                    early_stop = True\n",
    "                    print('Early stopping')\n",
    "                    break\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(loss_train, 'r', label='Train loss')\n",
    "plt.plot(loss_val, 'g', label='Val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot(accuracy_val, 'r', label='Val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}